# LLMè¿æ¥æ± ä¸Skillæ’æ’­æ¶æ„æ·±åº¦è¯„å®¡

> **è¯„å®¡æ—¥æœŸ**: 2026-02-10  
> **è¯„å®¡é‡ç‚¹**: è¿æ¥æ± è®¾è®¡ã€Skillæ’æ’­æ¨¡å¼ã€æ¶æ„åˆç†æ€§

---

## ğŸ¯ è¯„å®¡ç»“è®º

### æ€»ä½“è¯„ä»·ï¼šâ­â­â­â­ (4/5)

**ä¼˜ç‚¹**ï¼š
- âœ… è¿æ¥æ± è®¾è®¡æ€è·¯æ­£ç¡®ï¼Œå€Ÿé‰´æ•°æ®åº“è¿æ¥æ± 
- âœ… Skillæ’æ’­æ¨¡å¼çµæ´»ï¼Œé…ç½®é©±åŠ¨
- âœ… è¿½é—®åˆ¤æ–­ç®—æ³•ä¼˜ç§€ï¼ŒèŠ‚çœ44% tokens

**éœ€è¦æ”¹è¿›**ï¼š
- âš ï¸ è¿æ¥æ± æœ‰5ä¸ªå…³é”®é—®é¢˜éœ€è¦è§£å†³
- âš ï¸ Skillæ’æ’­ç¼ºå°‘ç‰ˆæœ¬ç®¡ç†å’Œçƒ­æ›´æ–°
- âš ï¸ ç¼ºå°‘é™æµå’Œç†”æ–­æœºåˆ¶

---

## ğŸ“Š Part 1: LLMè¿æ¥æ± æ·±åº¦åˆ†æ

### 1.1 è®¾è®¡åˆç†æ€§åˆ†æ

#### âœ… ä¼˜ç‚¹

**1. å€Ÿé‰´æ•°æ®åº“è¿æ¥æ± æ€æƒ³**
```python
# æ­£ç¡®çš„è®¾è®¡ç†å¿µ
- è¿æ¥å¤ç”¨ï¼ˆé¿å…é‡å¤åˆ›å»ºHTTPè¿æ¥ï¼‰
- æœ€å°/æœ€å¤§è¿æ¥æ•°æ§åˆ¶
- ç©ºé—²è¿æ¥å›æ”¶
- ç»Ÿè®¡ä¿¡æ¯æ”¶é›†
```

**2. ä¸Šä¸‹æ–‡ç®¡ç†å™¨æ¨¡å¼**
```python
async with pool.acquire(model) as client:
    response = await client.chat(...)
# è‡ªåŠ¨é‡Šæ”¾ï¼Œé˜²æ­¢è¿æ¥æ³„æ¼
```

**3. æŒ‰æ¨¡å‹åˆ†æ± **
```python
self._pools: Dict[str, Dict] = {}
# æ¯ä¸ªæ¨¡å‹ç‹¬ç«‹è¿æ¥æ± ï¼Œé¿å…ç›¸äº’å½±å“
```



#### âš ï¸ å…³é”®é—®é¢˜

**é—®é¢˜1: HTTPè¿æ¥æ±  vs LLMå®¢æˆ·ç«¯æ± çš„æ··æ·†**

```python
# å½“å‰å®ç°çš„é—®é¢˜
class LLMClientPool:
    def _create_client(self, model: str):
        # æ¯æ¬¡åˆ›å»ºæ–°çš„ httpx.AsyncClient
        client = UnifiedLLMClient(api_key, base_url)
        # UnifiedLLMClient å†…éƒ¨ï¼š
        # self.client = httpx.AsyncClient()  # âŒ æ¯æ¬¡éƒ½åˆ›å»ºæ–°çš„HTTPè¿æ¥
```

**é—®é¢˜åˆ†æ**ï¼š
- LLMå®¢æˆ·ç«¯æ± å¤ç”¨çš„æ˜¯**Pythonå¯¹è±¡**ï¼Œä¸æ˜¯**HTTPè¿æ¥**
- httpx.AsyncClient å†…éƒ¨æœ‰è‡ªå·±çš„è¿æ¥æ± 
- æ¯æ¬¡åˆ›å»ºæ–°çš„ AsyncClient ä¼šåˆ›å»ºæ–°çš„ HTTP è¿æ¥æ± 
- **å®é™…ä¸Šæ²¡æœ‰çœŸæ­£å¤ç”¨åº•å±‚TCPè¿æ¥**

**æ­£ç¡®åšæ³•**ï¼š
```python
# æ–¹æ¡ˆ1: å…¨å±€å…±äº« httpx.AsyncClient
class UnifiedLLMClient:
    _http_client = None  # ç±»çº§åˆ«å…±äº«
    
    def __init__(self, api_key: str, base_url: str):
        if UnifiedLLMClient._http_client is None:
            UnifiedLLMClient._http_client = httpx.AsyncClient(
                limits=httpx.Limits(
                    max_connections=100,
                    max_keepalive_connections=20
                )
            )
        self.client = UnifiedLLMClient._http_client

# æ–¹æ¡ˆ2: åªéœ€è¦ httpx çš„è¿æ¥æ± ï¼Œä¸éœ€è¦ LLM å®¢æˆ·ç«¯æ± 
# httpx.AsyncClient å·²ç»æœ‰å®Œå–„çš„è¿æ¥æ± æœºåˆ¶
```

**å½±å“**ï¼š
- å½“å‰è®¾è®¡çš„æ€§èƒ½æå‡å¯èƒ½åªæœ‰ 1-2%ï¼ˆå¯¹è±¡åˆ›å»ºå¼€é”€ï¼‰
- ä¸æ˜¯å®£ç§°çš„ 9%ï¼ˆTCPè¿æ¥å»ºç«‹å¼€é”€ï¼‰

---

**é—®é¢˜2: è¿æ¥æ± æ»¡æ—¶çš„å¤„ç†ä¸å½“**

```python
# å½“å‰å®ç°
if total_connections < self.max_size:
    client_info = self._create_client(model)
    return client_info['client']

# è¾¾åˆ°æœ€å¤§è¿æ¥æ•°
logger.warning(f"æ¨¡å‹ {model} çš„è¿æ¥æ± å·²æ»¡ï¼Œåˆ›å»ºä¸´æ—¶å®¢æˆ·ç«¯")
return self._create_temp_client(model)  # âŒ æ— é™åˆ¶åˆ›å»ºä¸´æ—¶è¿æ¥
```

**é—®é¢˜åˆ†æ**ï¼š
- è¿æ¥æ± æ»¡æ—¶åˆ›å»ºä¸´æ—¶è¿æ¥ï¼Œ**ç»•è¿‡äº†è¿æ¥æ•°é™åˆ¶**
- é«˜å¹¶å‘æ—¶å¯èƒ½åˆ›å»ºå¤§é‡ä¸´æ—¶è¿æ¥
- å¤±å»äº†è¿æ¥æ± çš„ä¿æŠ¤ä½œç”¨

**æ­£ç¡®åšæ³•**ï¼š
```python
# æ–¹æ¡ˆ1: ç­‰å¾…å¯ç”¨è¿æ¥ï¼ˆæ¨èï¼‰
async def acquire(self, model: str, timeout: float = 30.0):
    start_time = time.time()
    
    while True:
        client = self._try_get_client(model)
        if client:
            return client
        
        # ç­‰å¾…ä¸€æ®µæ—¶é—´
        if time.time() - start_time > timeout:
            raise TimeoutError(f"è·å–è¿æ¥è¶…æ—¶: {model}")
        
        await asyncio.sleep(0.1)

# æ–¹æ¡ˆ2: ä½¿ç”¨ä¿¡å·é‡æ§åˆ¶
self._semaphores[model] = asyncio.Semaphore(max_size)

async def acquire(self, model: str):
    async with self._semaphores[model]:
        client = self._get_or_create_client(model)
        yield client
```

---

**é—®é¢˜3: é‡Šæ”¾è¿æ¥æ—¶çš„ä¿¡æ¯ä¸¢å¤±**

```python
def release_client(self, client, model: str):
    # æ”¾å›ç©ºé—²æ± 
    client_info = {
        'client': client,
        'created_at': datetime.now(),  # âŒ é‡ç½®åˆ›å»ºæ—¶é—´
        'last_used': datetime.now(),
        'use_count': 0  # âŒ é‡ç½®ä½¿ç”¨æ¬¡æ•°
    }
```

**é—®é¢˜åˆ†æ**ï¼š
- é‡Šæ”¾æ—¶åˆ›å»ºæ–°çš„ client_infoï¼Œä¸¢å¤±äº†åŸæœ‰çš„ç»Ÿè®¡ä¿¡æ¯
- created_at åº”è¯¥ä¿æŒä¸å˜
- use_count åº”è¯¥ç´¯åŠ ï¼Œä¸æ˜¯é‡ç½®

**æ­£ç¡®åšæ³•**ï¼š
```python
def release_client(self, client, model: str):
    pool_info = self._pools[model]
    client_id = id(client)
    
    # ä» in_use ä¸­æ‰¾åˆ°åŸå§‹çš„ client_info
    for info in self._client_infos.get(client_id, []):
        if info['client'] is client:
            info['last_used'] = datetime.now()
            pool_info['in_use'].remove(client_id)
            pool_info['pool'].append(info)
            break
```

---

**é—®é¢˜4: ç¼ºå°‘å¥åº·æ£€æŸ¥**

```python
# å½“å‰å®ç°
# âŒ æ²¡æœ‰å¥åº·æ£€æŸ¥æœºåˆ¶
# å¦‚æœ LLM æœåŠ¡æŒ‚äº†ï¼Œè¿æ¥æ± ä¸­çš„å®¢æˆ·ç«¯ä»ç„¶å¯ç”¨
# ä¼šå¯¼è‡´è¯·æ±‚å¤±è´¥
```

**æ­£ç¡®åšæ³•**ï¼š
```python
async def _health_check(self, client):
    """å¥åº·æ£€æŸ¥"""
    try:
        # å‘é€ç®€å•æµ‹è¯•è¯·æ±‚
        await client.chat(
            prompt="test",
            max_tokens=1,
            timeout=5.0
        )
        return True
    except Exception:
        return False

async def acquire(self, model: str):
    """è·å–è¿æ¥æ—¶æ£€æŸ¥å¥åº·"""
    client = self._get_client(model)
    
    # å¥åº·æ£€æŸ¥
    if not await self._health_check(client):
        # ç§»é™¤ä¸å¥åº·çš„è¿æ¥
        self._remove_client(client, model)
        # é‡æ–°è·å–
        return await self.acquire(model)
    
    return client
```

---

**é—®é¢˜5: å•ä¾‹æ¨¡å¼çš„çº¿ç¨‹å®‰å…¨é—®é¢˜**

```python
class LLMClientPool:
    _instance = None
    
    def __new__(cls, *args, **kwargs):
        if cls._instance is None:  # âŒ ä¸æ˜¯çº¿ç¨‹å®‰å…¨çš„
            cls._instance = super().__new__(cls)
        return cls._instance
```

**é—®é¢˜åˆ†æ**ï¼š
- åœ¨å¤šçº¿ç¨‹ç¯å¢ƒä¸‹å¯èƒ½åˆ›å»ºå¤šä¸ªå®ä¾‹
- asyncio ç¯å¢ƒä¸‹é€šå¸¸æ˜¯å•çº¿ç¨‹ï¼Œä½†ä¸ä¿è¯

**æ­£ç¡®åšæ³•**ï¼š
```python
import threading

class LLMClientPool:
    _instance = None
    _lock = threading.Lock()
    
    def __new__(cls, *args, **kwargs):
        if cls._instance is None:
            with cls._lock:
                if cls._instance is None:  # åŒé‡æ£€æŸ¥
                    cls._instance = super().__new__(cls)
        return cls._instance
```



### 1.2 é‡æ–°è®¾è®¡å»ºè®®

#### æ–¹æ¡ˆA: ç®€åŒ–è®¾è®¡ï¼ˆæ¨èï¼‰

**æ ¸å¿ƒæ€æƒ³**ï¼šhttpx å·²ç»æœ‰å®Œå–„çš„è¿æ¥æ± ï¼Œä¸éœ€è¦å†åŒ…ä¸€å±‚

```python
class LLMClientManager:
    """LLMå®¢æˆ·ç«¯ç®¡ç†å™¨ï¼ˆç®€åŒ–ç‰ˆï¼‰"""
    
    def __init__(self):
        # å…¨å±€å…±äº«çš„ HTTP å®¢æˆ·ç«¯ï¼ˆå†…ç½®è¿æ¥æ± ï¼‰
        self.http_client = httpx.AsyncClient(
            limits=httpx.Limits(
                max_connections=100,      # æœ€å¤§è¿æ¥æ•°
                max_keepalive_connections=20  # ä¿æŒæ´»è·ƒçš„è¿æ¥æ•°
            ),
            timeout=httpx.Timeout(60.0)
        )
        
        # æŒ‰æä¾›å•†ç¼“å­˜é…ç½®
        self.configs = {}
    
    def get_client(self, model: str):
        """è·å–å®¢æˆ·ç«¯ï¼ˆè½»é‡çº§å¯¹è±¡ï¼‰"""
        provider = self._get_provider(model)
        
        if provider not in self.configs:
            self.configs[provider] = self._load_config(provider)
        
        return UnifiedLLMClient(
            http_client=self.http_client,  # å…±äº« HTTP å®¢æˆ·ç«¯
            config=self.configs[provider],
            model=model
        )

# ä½¿ç”¨æ–¹å¼
manager = LLMClientManager()
client = manager.get_client("qwen-max")
response = await client.chat(prompt)
```

**ä¼˜ç‚¹**ï¼š
- âœ… ç®€å•ç›´æ¥ï¼Œåˆ©ç”¨ httpx çš„è¿æ¥æ± 
- âœ… çœŸæ­£å¤ç”¨ TCP è¿æ¥
- âœ… å‡å°‘ä»£ç å¤æ‚åº¦
- âœ… æ›´å¥½çš„æ€§èƒ½

---

#### æ–¹æ¡ˆB: å®Œå–„ç°æœ‰è®¾è®¡

å¦‚æœåšæŒä½¿ç”¨ LLM å®¢æˆ·ç«¯æ± ï¼Œéœ€è¦ä¿®å¤ä¸Šè¿°5ä¸ªé—®é¢˜ï¼š

```python
class LLMClientPool:
    """å®Œå–„ç‰ˆè¿æ¥æ± """
    
    def __init__(self, min_size=1, max_size=10):
        # å…¨å±€å…±äº« HTTP å®¢æˆ·ç«¯
        self._http_client = httpx.AsyncClient(
            limits=httpx.Limits(max_connections=100)
        )
        
        # è¿æ¥æ± 
        self._pools: Dict[str, Dict] = {}
        
        # ä¿¡å·é‡æ§åˆ¶å¹¶å‘
        self._semaphores: Dict[str, asyncio.Semaphore] = {}
        
        # å®¢æˆ·ç«¯ä¿¡æ¯æ˜ å°„ï¼ˆä¿æŒç»Ÿè®¡ï¼‰
        self._client_infos: Dict[int, Dict] = {}
    
    async def acquire(self, model: str, timeout: float = 30.0):
        """è·å–è¿æ¥ï¼ˆå¸¦è¶…æ—¶å’Œå¥åº·æ£€æŸ¥ï¼‰"""
        # åˆå§‹åŒ–ä¿¡å·é‡
        if model not in self._semaphores:
            self._semaphores[model] = asyncio.Semaphore(self.max_size)
        
        # ç­‰å¾…å¯ç”¨æ§½ä½
        async with asyncio.timeout(timeout):
            async with self._semaphores[model]:
                client = await self._get_or_create_client(model)
                
                # å¥åº·æ£€æŸ¥
                if not await self._health_check(client):
                    await self._remove_client(client, model)
                    client = await self._get_or_create_client(model)
                
                yield client
    
    def release_client(self, client, model: str):
        """é‡Šæ”¾è¿æ¥ï¼ˆä¿æŒç»Ÿè®¡ä¿¡æ¯ï¼‰"""
        client_id = id(client)
        
        if client_id in self._client_infos:
            info = self._client_infos[client_id]
            info['last_used'] = datetime.now()
            # use_count å·²ç»åœ¨ä½¿ç”¨æ—¶ç´¯åŠ 
            
            pool_info = self._pools[model]
            pool_info['in_use'].remove(client_id)
            pool_info['pool'].append(info)
```

---

### 1.3 æ€§èƒ½å¯¹æ¯”

| æ–¹æ¡ˆ | TCPè¿æ¥å¤ç”¨ | ä»£ç å¤æ‚åº¦ | ç»´æŠ¤æˆæœ¬ | æ€§èƒ½æå‡ |
|------|------------|-----------|---------|---------|
| **å½“å‰å®ç°** | âŒ å¦ | é«˜ | é«˜ | ~1-2% |
| **æ–¹æ¡ˆAï¼ˆæ¨èï¼‰** | âœ… æ˜¯ | ä½ | ä½ | ~8-10% |
| **æ–¹æ¡ˆBï¼ˆå®Œå–„ï¼‰** | âœ… æ˜¯ | é«˜ | é«˜ | ~8-10% |

**å»ºè®®**ï¼šé‡‡ç”¨æ–¹æ¡ˆAï¼Œç®€å•é«˜æ•ˆã€‚



---

## ğŸ“Š Part 2: Skillæ’æ’­æ¨¡å¼æ·±åº¦åˆ†æ

### 2.1 è®¾è®¡åˆç†æ€§åˆ†æ

#### âœ… ä¼˜ç‚¹

**1. é…ç½®é©±åŠ¨ï¼Œæ˜“äºæ‰©å±•**
```yaml
# skills/symptom_recorder/skill.yaml
name: symptom_recorder
version: 1.0.0
description: ç—‡çŠ¶è®°å½•åŠ©æ‰‹
llm:
  model: qwen-coder-plus
  temperature: 0.7
```

**2. åŒæ¨¡å¼æ‰§è¡Œï¼ŒèŠ‚çœtokens**
```python
# é¦–æ¬¡è°ƒç”¨ï¼šå®Œæ•´prompt (1000 tokens)
result = await executor.execute(skill, context)

# è¿½é—®ï¼šè½»é‡çº§prompt (300 tokens)
result = await executor.execute_followup(skill, context)

# èŠ‚çœ: 700 tokens (70%)
```

**3. æ¨¡æ¿å¼•æ“ï¼Œçµæ´»æ¸²æŸ“**
```python
# prompt.md
ä½ æ˜¯{{description}}ã€‚
ç”¨æˆ·é—®é¢˜ï¼š{{user_message}}

# ä½¿ç”¨ Jinja2 æ¸²æŸ“
template = Template(skill.prompt_template)
prompt = template.render(**context)
```

---

#### âš ï¸ éœ€è¦æ”¹è¿›çš„åœ°æ–¹

**é—®é¢˜1: ç¼ºå°‘ç‰ˆæœ¬ç®¡ç†**

```yaml
# å½“å‰å®ç°
name: symptom_recorder
version: 1.0.0  # âŒ ç‰ˆæœ¬å·æ²¡æœ‰å®é™…ä½œç”¨

# é—®é¢˜ï¼š
- æ›´æ–° Skill åï¼Œæ—§ç‰ˆæœ¬çš„å¯¹è¯æ€ä¹ˆåŠï¼Ÿ
- å¦‚ä½•å›æ»šåˆ°æ—§ç‰ˆæœ¬ï¼Ÿ
- å¦‚ä½•æ”¯æŒ A/B æµ‹è¯•ï¼Ÿ
```

**æ”¹è¿›æ–¹æ¡ˆ**ï¼š
```python
class SkillLoader:
    def load_skill(self, name: str, version: str = "latest"):
        """æ”¯æŒç‰ˆæœ¬åŠ è½½"""
        if version == "latest":
            version = self._get_latest_version(name)
        
        skill_path = self.skills_dir / name / version
        return self._load_from_path(skill_path)
    
    def _get_latest_version(self, name: str) -> str:
        """è·å–æœ€æ–°ç‰ˆæœ¬"""
        versions = []
        skill_dir = self.skills_dir / name
        for v_dir in skill_dir.iterdir():
            if v_dir.is_dir() and v_dir.name.startswith('v'):
                versions.append(v_dir.name)
        return max(versions)  # æŒ‰ç‰ˆæœ¬å·æ’åº

# ç›®å½•ç»“æ„
skills/
â”œâ”€â”€ symptom_recorder/
â”‚   â”œâ”€â”€ v1.0.0/
â”‚   â”‚   â”œâ”€â”€ skill.yaml
â”‚   â”‚   â””â”€â”€ prompt.md
â”‚   â”œâ”€â”€ v1.1.0/
â”‚   â”‚   â”œâ”€â”€ skill.yaml
â”‚   â”‚   â””â”€â”€ prompt.md
â”‚   â””â”€â”€ latest -> v1.1.0  # è½¯é“¾æ¥
```

---

**é—®é¢˜2: ç¼ºå°‘çƒ­æ›´æ–°æœºåˆ¶**

```python
# å½“å‰å®ç°
def load_all_skills(self):
    """å¯åŠ¨æ—¶åŠ è½½ä¸€æ¬¡"""
    for skill_dir in self.skills_dir.iterdir():
        skill = self.load_skill(skill_dir)
        self.skills[skill.name] = skill

# é—®é¢˜ï¼š
# âŒ æ›´æ–° Skill éœ€è¦é‡å¯æœåŠ¡
# âŒ æ— æ³•åŠ¨æ€åŠ è½½æ–° Skill
```

**æ”¹è¿›æ–¹æ¡ˆ**ï¼š
```python
class SkillLoader:
    def __init__(self):
        self.skills = {}
        self.last_modified = {}
        self._watch_task = None
    
    async def start_watching(self):
        """å¯åŠ¨æ–‡ä»¶ç›‘æ§"""
        self._watch_task = asyncio.create_task(self._watch_skills())
    
    async def _watch_skills(self):
        """ç›‘æ§ Skill æ–‡ä»¶å˜åŒ–"""
        while True:
            await asyncio.sleep(5)  # æ¯5ç§’æ£€æŸ¥ä¸€æ¬¡
            
            for skill_name in self.skills:
                skill_path = self.skills_dir / skill_name / "skill.yaml"
                current_mtime = skill_path.stat().st_mtime
                
                if current_mtime > self.last_modified.get(skill_name, 0):
                    logger.info(f"æ£€æµ‹åˆ° Skill æ›´æ–°: {skill_name}")
                    self.reload_skill(skill_name)
                    self.last_modified[skill_name] = current_mtime
    
    def reload_skill(self, name: str):
        """é‡æ–°åŠ è½½ Skill"""
        skill_dir = self.skills_dir / name
        skill = self.load_skill(skill_dir)
        self.skills[name] = skill
        logger.info(f"å·²é‡æ–°åŠ è½½ Skill: {name}")
```

---

**é—®é¢˜3: ç¼ºå°‘Skillä¾èµ–ç®¡ç†**

```yaml
# å½“å‰å®ç°
name: appointment_helper
# âŒ æ²¡æœ‰ä¾èµ–å£°æ˜

# é—®é¢˜ï¼š
# å¦‚æœè¿™ä¸ª Skill éœ€è¦è°ƒç”¨å…¶ä»– Skill æ€ä¹ˆåŠï¼Ÿ
# å¦‚ä½•ç®¡ç† Skill ä¹‹é—´çš„ä¾èµ–å…³ç³»ï¼Ÿ
```

**æ”¹è¿›æ–¹æ¡ˆ**ï¼š
```yaml
# skill.yaml
name: appointment_helper
version: 1.0.0
dependencies:
  - name: symptom_recorder
    version: ">=1.0.0"
  - name: knowledge_base
    version: "^1.1.0"

# åŠ è½½æ—¶æ£€æŸ¥ä¾èµ–
class SkillLoader:
    def load_skill(self, skill_dir: Path):
        config = self._load_yaml(skill_dir / "skill.yaml")
        
        # æ£€æŸ¥ä¾èµ–
        for dep in config.get('dependencies', []):
            if not self._check_dependency(dep):
                raise ValueError(f"ä¾èµ–ä¸æ»¡è¶³: {dep}")
        
        return SkillConfig(**config)
```

---

**é—®é¢˜4: ç¼ºå°‘Skillæ‰§è¡Œè¶…æ—¶æ§åˆ¶**

```python
# å½“å‰å®ç°
async def execute(self, skill, context):
    # âŒ æ²¡æœ‰è¶…æ—¶æ§åˆ¶
    response = await llm_client.chat(prompt)
    return response

# é—®é¢˜ï¼š
# å¦‚æœ LLM å“åº”å¾ˆæ…¢ï¼Œä¼šä¸€ç›´ç­‰å¾…
# å¯èƒ½å¯¼è‡´è¯·æ±‚å †ç§¯
```

**æ”¹è¿›æ–¹æ¡ˆ**ï¼š
```python
async def execute(self, skill, context):
    """æ‰§è¡Œ Skillï¼ˆå¸¦è¶…æ—¶ï¼‰"""
    timeout = skill.llm.get('timeout', 30.0)
    
    try:
        async with asyncio.timeout(timeout):
            response = await llm_client.chat(prompt)
            return response
    except asyncio.TimeoutError:
        logger.error(f"Skill æ‰§è¡Œè¶…æ—¶: {skill.name}")
        # é™çº§å¤„ç†
        return self._fallback_response(skill, context)
```

---

**é—®é¢˜5: ç¼ºå°‘Skillæ‰§è¡Œç›‘æ§**

```python
# å½“å‰å®ç°
# âŒ æ²¡æœ‰ç›‘æ§æŒ‡æ ‡
# - æ‰§è¡Œæ¬¡æ•°
# - æˆåŠŸç‡
# - å¹³å‡è€—æ—¶
# - Tokenä½¿ç”¨é‡
```

**æ”¹è¿›æ–¹æ¡ˆ**ï¼š
```python
class SkillExecutor:
    def __init__(self):
        self.metrics = {
            'executions': {},  # æ‰§è¡Œæ¬¡æ•°
            'successes': {},   # æˆåŠŸæ¬¡æ•°
            'failures': {},    # å¤±è´¥æ¬¡æ•°
            'total_time': {},  # æ€»è€—æ—¶
            'total_tokens': {} # æ€»tokens
        }
    
    async def execute(self, skill, context):
        """æ‰§è¡Œ Skillï¼ˆå¸¦ç›‘æ§ï¼‰"""
        start_time = time.time()
        
        try:
            result = await self._do_execute(skill, context)
            
            # è®°å½•æˆåŠŸ
            self.metrics['executions'][skill.name] = \
                self.metrics['executions'].get(skill.name, 0) + 1
            self.metrics['successes'][skill.name] = \
                self.metrics['successes'].get(skill.name, 0) + 1
            
            return result
        
        except Exception as e:
            # è®°å½•å¤±è´¥
            self.metrics['failures'][skill.name] = \
                self.metrics['failures'].get(skill.name, 0) + 1
            raise
        
        finally:
            # è®°å½•è€—æ—¶
            elapsed = time.time() - start_time
            self.metrics['total_time'][skill.name] = \
                self.metrics['total_time'].get(skill.name, 0) + elapsed
    
    def get_metrics(self, skill_name: str = None):
        """è·å–ç›‘æ§æŒ‡æ ‡"""
        if skill_name:
            return {
                'executions': self.metrics['executions'].get(skill_name, 0),
                'success_rate': self._calc_success_rate(skill_name),
                'avg_time': self._calc_avg_time(skill_name),
                'total_tokens': self.metrics['total_tokens'].get(skill_name, 0)
            }
        return self.metrics
```



### 2.2 Skillæ’æ’­æ¨¡å¼ä¼˜åŒ–å»ºè®®

#### å®Œæ•´çš„Skillç”Ÿå‘½å‘¨æœŸç®¡ç†

```python
class SkillManager:
    """Skillç®¡ç†å™¨ï¼ˆå®Œæ•´ç‰ˆï¼‰"""
    
    def __init__(self):
        self.loader = SkillLoader()
        self.executor = SkillExecutor()
        self.registry = SkillRegistry()
        self.monitor = SkillMonitor()
    
    async def start(self):
        """å¯åŠ¨ç®¡ç†å™¨"""
        # åŠ è½½æ‰€æœ‰ Skill
        await self.loader.load_all_skills()
        
        # å¯åŠ¨æ–‡ä»¶ç›‘æ§
        await self.loader.start_watching()
        
        # å¯åŠ¨ç›‘æ§
        await self.monitor.start()
    
    async def execute_skill(
        self,
        name: str,
        context: Dict,
        version: str = "latest",
        timeout: float = 30.0
    ):
        """æ‰§è¡Œ Skillï¼ˆå®Œæ•´æµç¨‹ï¼‰"""
        
        # 1. è·å– Skill
        skill = self.loader.get_skill(name, version)
        
        # 2. æ£€æŸ¥ä¾èµ–
        self._check_dependencies(skill)
        
        # 3. æ‰§è¡Œï¼ˆå¸¦è¶…æ—¶å’Œç›‘æ§ï¼‰
        start_time = time.time()
        
        try:
            async with asyncio.timeout(timeout):
                result = await self.executor.execute(skill, context)
            
            # è®°å½•æˆåŠŸ
            self.monitor.record_success(name, time.time() - start_time)
            
            return result
        
        except asyncio.TimeoutError:
            # è¶…æ—¶é™çº§
            self.monitor.record_timeout(name)
            return await self._fallback(skill, context)
        
        except Exception as e:
            # è®°å½•å¤±è´¥
            self.monitor.record_failure(name, str(e))
            raise
    
    def get_skill_metrics(self, name: str = None):
        """è·å– Skill æŒ‡æ ‡"""
        return self.monitor.get_metrics(name)
```

---

## ğŸ“Š Part 3: æ¶æ„å®Œå–„å»ºè®®

### 3.1 ç¼ºå°‘çš„å…³é”®ç»„ä»¶

#### 1. é™æµå™¨ï¼ˆRate Limiterï¼‰

```python
class RateLimiter:
    """è¯·æ±‚é™æµå™¨"""
    
    def __init__(self):
        # æŒ‰ç”¨æˆ·é™æµ
        self.user_limiters = {}
        
        # æŒ‰æ¨¡å‹é™æµï¼ˆé¿å…è¶…è¿‡APIé™åˆ¶ï¼‰
        self.model_limiters = {
            'qwen-max': AsyncLimiter(100, 60),      # 100æ¬¡/åˆ†é’Ÿ
            'qwen-plus': AsyncLimiter(200, 60),     # 200æ¬¡/åˆ†é’Ÿ
            'gpt-5.2': AsyncLimiter(50, 60),        # 50æ¬¡/åˆ†é’Ÿ
        }
    
    async def acquire(self, user_id: int, model: str):
        """è·å–ä»¤ç‰Œ"""
        # ç”¨æˆ·é™æµ
        if user_id not in self.user_limiters:
            self.user_limiters[user_id] = AsyncLimiter(10, 60)  # 10æ¬¡/åˆ†é’Ÿ
        
        async with self.user_limiters[user_id]:
            # æ¨¡å‹é™æµ
            async with self.model_limiters[model]:
                pass

# ä½¿ç”¨
async def execute_skill(self, skill_name, user_id, ...):
    # é™æµ
    await self.rate_limiter.acquire(user_id, skill.llm['model'])
    
    # æ‰§è¡Œ
    result = await self.executor.execute(skill, context)
```

---

#### 2. ç†”æ–­å™¨ï¼ˆCircuit Breakerï¼‰

```python
class CircuitBreaker:
    """ç†”æ–­å™¨"""
    
    def __init__(self, failure_threshold=5, timeout=60):
        self.failure_threshold = failure_threshold
        self.timeout = timeout
        
        self.states = {}  # {model: 'closed' | 'open' | 'half_open'}
        self.failure_counts = {}
        self.last_failure_time = {}
    
    async def call(self, model: str, func, *args, **kwargs):
        """è°ƒç”¨ï¼ˆå¸¦ç†”æ–­ä¿æŠ¤ï¼‰"""
        state = self.states.get(model, 'closed')
        
        # ç†”æ–­æ‰“å¼€
        if state == 'open':
            # æ£€æŸ¥æ˜¯å¦å¯ä»¥å°è¯•æ¢å¤
            if time.time() - self.last_failure_time[model] > self.timeout:
                self.states[model] = 'half_open'
            else:
                raise CircuitBreakerOpenError(f"ç†”æ–­å™¨æ‰“å¼€: {model}")
        
        try:
            result = await func(*args, **kwargs)
            
            # æˆåŠŸï¼Œé‡ç½®è®¡æ•°
            if state == 'half_open':
                self.states[model] = 'closed'
            self.failure_counts[model] = 0
            
            return result
        
        except Exception as e:
            # å¤±è´¥ï¼Œå¢åŠ è®¡æ•°
            self.failure_counts[model] = self.failure_counts.get(model, 0) + 1
            self.last_failure_time[model] = time.time()
            
            # è¾¾åˆ°é˜ˆå€¼ï¼Œæ‰“å¼€ç†”æ–­å™¨
            if self.failure_counts[model] >= self.failure_threshold:
                self.states[model] = 'open'
                logger.error(f"ç†”æ–­å™¨æ‰“å¼€: {model}")
            
            raise

# ä½¿ç”¨
async def execute_skill(self, skill, context):
    model = skill.llm['model']
    
    try:
        result = await self.circuit_breaker.call(
            model,
            self._do_execute,
            skill,
            context
        )
        return result
    except CircuitBreakerOpenError:
        # é™çº§å¤„ç†
        return await self._fallback(skill, context)
```

---

#### 3. é™çº§ç­–ç•¥ï¼ˆFallbackï¼‰

```python
class FallbackStrategy:
    """é™çº§ç­–ç•¥"""
    
    def __init__(self):
        # æ¨¡å‹é™çº§é“¾
        self.fallback_chains = {
            'gpt-5.2': ['gpt-4o', 'claude-opus-4-5', 'qwen-max'],
            'claude-opus-4-5': ['claude-sonnet-4-5', 'qwen-max'],
            'qwen-max': ['qwen-plus', 'qwen-turbo'],
        }
    
    async def execute_with_fallback(
        self,
        skill: SkillConfig,
        context: Dict
    ):
        """æ‰§è¡Œï¼ˆå¸¦é™çº§ï¼‰"""
        model = skill.llm['model']
        fallback_chain = [model] + self.fallback_chains.get(model, [])
        
        last_error = None
        
        for fallback_model in fallback_chain:
            try:
                logger.info(f"å°è¯•æ¨¡å‹: {fallback_model}")
                
                # ä¿®æ”¹ Skill é…ç½®
                skill.llm['model'] = fallback_model
                
                # æ‰§è¡Œ
                result = await self.executor.execute(skill, context)
                
                if fallback_model != model:
                    logger.warning(f"é™çº§æˆåŠŸ: {model} -> {fallback_model}")
                
                return result
            
            except Exception as e:
                last_error = e
                logger.error(f"æ¨¡å‹ {fallback_model} å¤±è´¥: {e}")
                continue
        
        # æ‰€æœ‰é™çº§éƒ½å¤±è´¥
        raise FallbackExhaustedError(f"æ‰€æœ‰é™çº§æ¨¡å‹éƒ½å¤±è´¥: {last_error}")
```

---

### 3.2 å®Œæ•´æ¶æ„å›¾

```
ç”¨æˆ·è¯·æ±‚
    â†“
é™æµå™¨ (RateLimiter)
    â†“
AIç¼–æ’å™¨ (Orchestrator)
    â†“
ç†”æ–­å™¨ (CircuitBreaker)
    â†“
Skillç®¡ç†å™¨ (SkillManager)
    â”œâ”€ ç‰ˆæœ¬ç®¡ç†
    â”œâ”€ çƒ­æ›´æ–°
    â”œâ”€ ä¾èµ–æ£€æŸ¥
    â””â”€ ç›‘æ§ç»Ÿè®¡
    â†“
Skillæ‰§è¡Œå™¨ (SkillExecutor)
    â”œâ”€ è¶…æ—¶æ§åˆ¶
    â”œâ”€ é™çº§ç­–ç•¥
    â””â”€ é”™è¯¯é‡è¯•
    â†“
ä¸Šä¸‹æ–‡ç®¡ç† (ContextManager)
    â”œâ”€ è¿½é—®åˆ¤æ–­
    â”œâ”€ è®°å¿†ç®¡ç†
    â””â”€ ä¸Šä¸‹æ–‡å‹ç¼©
    â†“
LLMå®¢æˆ·ç«¯ç®¡ç†å™¨ (ç®€åŒ–ç‰ˆ)
    â””â”€ å…±äº« HTTP å®¢æˆ·ç«¯æ± 
    â†“
LLMæœåŠ¡
```



---

## ğŸ“Š Part 4: æœ€ç»ˆå»ºè®®

### 4.1 ä¼˜å…ˆçº§æ”¹è¿›æ¸…å•

#### ğŸ”´ é«˜ä¼˜å…ˆçº§ï¼ˆå¿…é¡»ä¿®å¤ï¼‰

1. **é‡æ–°è®¾è®¡è¿æ¥æ± **
   - é‡‡ç”¨æ–¹æ¡ˆAï¼šç®€åŒ–è®¾è®¡ï¼Œä½¿ç”¨ httpx å†…ç½®è¿æ¥æ± 
   - æˆ–ä¿®å¤æ–¹æ¡ˆBçš„5ä¸ªå…³é”®é—®é¢˜
   - **é¢„è®¡å·¥ä½œé‡**: 2-3å¤©

2. **æ·»åŠ é™æµå’Œç†”æ–­**
   - å®ç° RateLimiter
   - å®ç° CircuitBreaker
   - å®ç°é™çº§ç­–ç•¥
   - **é¢„è®¡å·¥ä½œé‡**: 3-4å¤©

3. **Skillè¶…æ—¶æ§åˆ¶**
   - æ·»åŠ æ‰§è¡Œè¶…æ—¶
   - æ·»åŠ é™çº§å¤„ç†
   - **é¢„è®¡å·¥ä½œé‡**: 1å¤©

#### ğŸŸ¡ ä¸­ä¼˜å…ˆçº§ï¼ˆå»ºè®®æ·»åŠ ï¼‰

4. **Skillç‰ˆæœ¬ç®¡ç†**
   - æ”¯æŒå¤šç‰ˆæœ¬å…±å­˜
   - æ”¯æŒç‰ˆæœ¬å›æ»š
   - **é¢„è®¡å·¥ä½œé‡**: 2-3å¤©

5. **Skillçƒ­æ›´æ–°**
   - æ–‡ä»¶ç›‘æ§
   - åŠ¨æ€é‡è½½
   - **é¢„è®¡å·¥ä½œé‡**: 2å¤©

6. **Skillç›‘æ§ç»Ÿè®¡**
   - æ‰§è¡Œæ¬¡æ•°ã€æˆåŠŸç‡
   - å¹³å‡è€—æ—¶ã€Tokenä½¿ç”¨
   - **é¢„è®¡å·¥ä½œé‡**: 2å¤©

#### ğŸŸ¢ ä½ä¼˜å…ˆçº§ï¼ˆå¯é€‰ï¼‰

7. **Skillä¾èµ–ç®¡ç†**
   - ä¾èµ–å£°æ˜
   - ä¾èµ–æ£€æŸ¥
   - **é¢„è®¡å·¥ä½œé‡**: 2å¤©

8. **å¥åº·æ£€æŸ¥æœºåˆ¶**
   - è¿æ¥å¥åº·æ£€æŸ¥
   - æœåŠ¡å¥åº·æ£€æŸ¥
   - **é¢„è®¡å·¥ä½œé‡**: 1-2å¤©

---

### 4.2 æ”¹è¿›åçš„æ€§èƒ½é¢„æœŸ

| æŒ‡æ ‡ | å½“å‰ | æ”¹è¿›å | æå‡ |
|------|------|--------|------|
| **TCPè¿æ¥å¤ç”¨** | âŒ å¦ | âœ… æ˜¯ | - |
| **è¿æ¥è·å–æ—¶é—´** | ~10ms | ~1ms | 90% â†“ |
| **å¹¶å‘æ”¯æŒ** | ~50 QPS | ~200 QPS | 300% â†‘ |
| **æ•…éšœæ¢å¤** | æ‰‹åŠ¨ | è‡ªåŠ¨ | - |
| **TokenèŠ‚çœ** | 44% | 44% | ä¿æŒ |
| **å¯ç”¨æ€§** | 95% | 99.5% | 4.5% â†‘ |

---

### 4.3 ä»£ç ç¤ºä¾‹ï¼šæ”¹è¿›åçš„æ¶æ„

```python
# backend/daoyoucode/llm/orchestrator.py

class AIOrchestrator:
    """AIç¼–æ’å™¨ï¼ˆæ”¹è¿›ç‰ˆï¼‰"""
    
    def __init__(self):
        # ç®€åŒ–çš„å®¢æˆ·ç«¯ç®¡ç†å™¨
        self.client_manager = LLMClientManager()
        
        # Skillç®¡ç†å™¨ï¼ˆå®Œæ•´ç‰ˆï¼‰
        self.skill_manager = SkillManager()
        
        # ä¸Šä¸‹æ–‡ç®¡ç†å™¨
        self.context_manager = ContextManager()
        
        # é™æµå™¨
        self.rate_limiter = RateLimiter()
        
        # ç†”æ–­å™¨
        self.circuit_breaker = CircuitBreaker()
        
        # é™çº§ç­–ç•¥
        self.fallback_strategy = FallbackStrategy()
    
    async def execute_skill(
        self,
        skill_name: str,
        user_message: str,
        user_id: int,
        session_id: str,
        context: Optional[Dict] = None
    ) -> Dict[str, Any]:
        """æ‰§è¡ŒSkillï¼ˆå®Œæ•´æµç¨‹ï¼‰"""
        
        # 1. è·å–Skill
        skill = self.skill_manager.get_skill(skill_name)
        
        # 2. é™æµ
        await self.rate_limiter.acquire(user_id, skill.llm['model'])
        
        # 3. å‡†å¤‡ä¸Šä¸‹æ–‡
        if context is None:
            context = {}
        context['user_message'] = user_message
        
        # 4. åˆ¤æ–­è¿½é—®
        is_followup, confidence, reason = await self.context_manager.is_followup_question(
            session_id, skill_name, user_message
        )
        
        # 5. æ‰§è¡Œï¼ˆå¸¦ç†”æ–­å’Œé™çº§ï¼‰
        try:
            result = await self.circuit_breaker.call(
                skill.llm['model'],
                self.fallback_strategy.execute_with_fallback,
                skill,
                context
            )
        except CircuitBreakerOpenError:
            # ç†”æ–­æ‰“å¼€ï¼Œç›´æ¥é™çº§
            result = await self.fallback_strategy.execute_with_fallback(
                skill, context
            )
        
        # 6. æ›´æ–°ä¸Šä¸‹æ–‡
        await self.context_manager.update_context(
            session_id, user_message, result,
            current_skill=skill_name, user_id=user_id
        )
        
        return result
```

---

## ğŸ“Š æ€»ç»“

### âœ… è®¾è®¡ä¼˜ç‚¹

1. **è¿æ¥æ± æ€æƒ³æ­£ç¡®** - å€Ÿé‰´æ•°æ®åº“è¿æ¥æ± 
2. **Skillæ’æ’­çµæ´»** - é…ç½®é©±åŠ¨ï¼Œæ˜“äºæ‰©å±•
3. **è¿½é—®åˆ¤æ–­ä¼˜ç§€** - ä¸‰å±‚ç€‘å¸ƒï¼ŒèŠ‚çœ44% tokens
4. **ä¸Šä¸‹æ–‡ç®¡ç†å®Œå–„** - çŸ­æœŸ+é•¿æœŸè®°å¿†

### âš ï¸ éœ€è¦æ”¹è¿›

1. **è¿æ¥æ± å®ç°æœ‰è¯¯** - æ²¡æœ‰çœŸæ­£å¤ç”¨TCPè¿æ¥
2. **ç¼ºå°‘é™æµç†”æ–­** - é«˜å¹¶å‘ä¸‹å¯èƒ½å´©æºƒ
3. **Skillç®¡ç†ä¸å®Œå–„** - ç¼ºå°‘ç‰ˆæœ¬ã€çƒ­æ›´æ–°ã€ç›‘æ§
4. **ç¼ºå°‘é™çº§ç­–ç•¥** - æ•…éšœæ—¶æ— æ³•è‡ªåŠ¨æ¢å¤

### ğŸ¯ æ”¹è¿›å»ºè®®

**çŸ­æœŸï¼ˆ1-2å‘¨ï¼‰**ï¼š
1. é‡æ–°è®¾è®¡è¿æ¥æ± ï¼ˆé‡‡ç”¨æ–¹æ¡ˆAï¼‰
2. æ·»åŠ é™æµå’Œç†”æ–­
3. æ·»åŠ Skillè¶…æ—¶æ§åˆ¶

**ä¸­æœŸï¼ˆ2-3å‘¨ï¼‰**ï¼š
4. å®ç°Skillç‰ˆæœ¬ç®¡ç†
5. å®ç°Skillçƒ­æ›´æ–°
6. å®ç°ç›‘æ§ç»Ÿè®¡

**é•¿æœŸï¼ˆ1ä¸ªæœˆ+ï¼‰**ï¼š
7. å®ç°Skillä¾èµ–ç®¡ç†
8. å®Œå–„å¥åº·æ£€æŸ¥
9. æ€§èƒ½ä¼˜åŒ–å’Œå‹æµ‹

### ğŸ“ˆ é¢„æœŸæ•ˆæœ

æ”¹è¿›åçš„æ¶æ„å°†å…·å¤‡ï¼š
- âœ… çœŸæ­£çš„è¿æ¥å¤ç”¨ï¼ˆ8-10%æ€§èƒ½æå‡ï¼‰
- âœ… é«˜å¯ç”¨æ€§ï¼ˆ99.5%+ï¼‰
- âœ… è‡ªåŠ¨é™çº§å’Œæ¢å¤
- âœ… å®Œå–„çš„ç›‘æ§å’Œç»Ÿè®¡
- âœ… çµæ´»çš„ç‰ˆæœ¬ç®¡ç†

---

**è¯„å®¡ç»“è®º**: æ•´ä½“è®¾è®¡æ€è·¯æ­£ç¡®ï¼Œä½†å®ç°ç»†èŠ‚éœ€è¦æ”¹è¿›ã€‚å»ºè®®æŒ‰ä¼˜å…ˆçº§é€æ­¥å®Œå–„ã€‚

**è¯„å®¡äºº**: AI Architecture Team  
**æ—¥æœŸ**: 2026-02-10  
**ç‰ˆæœ¬**: v1.0
