# è°ƒç”¨é“¾è·¯åˆ†æ - 04 Agentå±‚

## 4. Agentå±‚ï¼šæ™ºèƒ½å†³ç­–

### å…¥å£å‡½æ•°
```
ğŸ“ backend/daoyoucode/agents/core/agent.py :: BaseAgent.execute()
```

### è°ƒç”¨æµç¨‹

#### 4.1 Agentæ‰§è¡Œå…¥å£

**ä»£ç **:
```python
async def execute(
    self,
    prompt_source: Dict[str, Any],
    user_input: str,
    context: Optional[Dict[str, Any]] = None,
    llm_config: Optional[Dict[str, Any]] = None,
    tools: Optional[List[str]] = None,
    max_tool_iterations: int = 5
) -> AgentResult:
    """
    æ‰§è¡Œä»»åŠ¡
    
    æµç¨‹ï¼š
    1. è·å–è®°å¿†ï¼ˆå¯¹è¯å†å²ã€ç”¨æˆ·åå¥½ã€ä»»åŠ¡å†å²ï¼‰
    2. åŠ è½½Prompt
    3. æ¸²æŸ“Prompt
    4. è°ƒç”¨LLMï¼ˆå¸¦æˆ–ä¸å¸¦å·¥å…·ï¼‰
    5. ä¿å­˜åˆ°è®°å¿†
    """
```

**èŒè´£**:
- åè°ƒæ•´ä¸ªæ‰§è¡Œæµç¨‹
- ç®¡ç†è®°å¿†ç³»ç»Ÿ
- è°ƒç”¨LLM
- å¤„ç†å·¥å…·è°ƒç”¨

---

#### 4.2 è®°å¿†åŠ è½½

**ä»£ç **:
```python
# æå–session_idå’Œuser_id
session_id = context.get('session_id', 'default')
user_id = context.get('user_id', session_id)

# 1. å¯¹è¯å†å²ï¼ˆLLMå±‚è®°å¿†ï¼‰
history = self.memory.get_conversation_history(session_id, limit=3)
if history:
    context['conversation_history'] = history

# 2. ç”¨æˆ·åå¥½ï¼ˆAgentå±‚è®°å¿†ï¼‰
prefs = self.memory.get_preferences(user_id)
if prefs:
    context['user_preferences'] = prefs

# 3. ä»»åŠ¡å†å²ï¼ˆAgentå±‚è®°å¿†ï¼‰
task_history = self.memory.get_task_history(user_id, limit=5)
if task_history:
    context['recent_tasks'] = task_history
```

**è®°å¿†ç±»å‹**:
- **å¯¹è¯å†å²** - æœ€è¿‘3è½®å¯¹è¯
- **ç”¨æˆ·åå¥½** - ç”¨æˆ·çš„ç¼–ç¨‹è¯­è¨€åå¥½ç­‰
- **ä»»åŠ¡å†å²** - æœ€è¿‘5ä¸ªä»»åŠ¡

---

#### 4.3 Promptå¤„ç†

**åŠ è½½Prompt**:
```python
prompt = await self._load_prompt(prompt_source, context)
```

**æ¸²æŸ“Prompt**ï¼ˆJinja2æ¨¡æ¿ï¼‰:
```python
def _render_prompt(self, prompt: str, user_input: str, context: Dict) -> str:
    """æ¸²æŸ“Promptï¼ˆæ”¯æŒJinja2æ¨¡æ¿ï¼‰"""
    try:
        from jinja2 import Template
        template = Template(prompt)
        return template.render(user_input=user_input, **context)
    except Exception as e:
        # å›é€€åˆ°ç®€å•æ›¿æ¢
        return prompt.replace('{{user_input}}', user_input)
```

---

#### 4.4 LLMè°ƒç”¨åˆ†æ”¯

**åˆ†æ”¯é€»è¾‘**:
```python
if tools:
    # ========== å¸¦å·¥å…·è°ƒç”¨ ==========
    # æ„å»ºåˆå§‹æ¶ˆæ¯ï¼ˆåŒ…å«å†å²å¯¹è¯ï¼‰
    initial_messages = []
    
    # æ·»åŠ å†å²å¯¹è¯
    if history:
        for h in history:
            initial_messages.append({
                "role": "user",
                "content": h.get('user', '')
            })
            initial_messages.append({
                "role": "assistant",
                "content": h.get('ai', '')
            })
    
    # æ·»åŠ å½“å‰ç”¨æˆ·è¾“å…¥
    initial_messages.append({
        "role": "user",
        "content": full_prompt
    })
    
    response, tools_used = await self._call_llm_with_tools(
        initial_messages,
        tools,
        llm_config,
        max_tool_iterations
    )
else:
    # ========== ä¸å¸¦å·¥å…·è°ƒç”¨ ==========
    response = await self._call_llm(full_prompt, llm_config)
```

**å†³ç­–ç‚¹**:
- å¦‚æœSkillé…ç½®äº†tools â†’ ä½¿ç”¨Function Calling
- å¦åˆ™ â†’ ç®€å•çš„LLMè°ƒç”¨

---

#### 4.5 Function Callingå¾ªç¯ï¼ˆæ ¸å¿ƒï¼‰

**å‡½æ•°**: `_call_llm_with_tools()`

**ä»£ç **:
```python
async def _call_llm_with_tools(
    self,
    initial_messages: List[Dict],
    tool_names: List[str],
    llm_config: Optional[Dict] = None,
    max_iterations: int = 5
) -> tuple[str, List[str]]:
    """
    è°ƒç”¨LLMå¹¶æ”¯æŒå·¥å…·è°ƒç”¨
    
    æµç¨‹ï¼š
    1. è·å–å·¥å…·çš„Function schemas
    2. è°ƒç”¨LLMï¼ˆå¸¦functionså‚æ•°ï¼‰
    3. æ£€æŸ¥æ˜¯å¦æœ‰function_call
    4. å¦‚æœæœ‰ï¼Œæ‰§è¡Œå·¥å…·
    5. å°†å·¥å…·ç»“æœæ·»åŠ åˆ°æ¶ˆæ¯å†å²
    6. é‡å¤æ­¥éª¤2-5ï¼Œç›´åˆ°LLMä¸å†è°ƒç”¨å·¥å…·æˆ–è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°
    """
    
    # è·å–å·¥å…·schemas
    function_schemas = tool_registry.get_function_schemas(tool_names)
    
    # ä½¿ç”¨åˆå§‹æ¶ˆæ¯ä½œä¸ºèµ·ç‚¹
    messages = initial_messages.copy()
    tools_used = []
    
    # å·¥å…·è°ƒç”¨å¾ªç¯
    for iteration in range(max_iterations):
        # 1. è°ƒç”¨LLMï¼ˆå¸¦å·¥å…·ï¼‰
        response = await self._call_llm_with_functions(
            messages,
            function_schemas,
            llm_config
        )
        
        # 2. æ£€æŸ¥æ˜¯å¦æœ‰function_call
        function_call = response.get('metadata', {}).get('function_call')
        
        if not function_call:
            # æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œè¿”å›æœ€ç»ˆå“åº”
            return response.get('content', ''), tools_used
        
        # 3. è§£æå·¥å…·è°ƒç”¨
        tool_name = function_call['name']
        tool_args = json.loads(function_call['arguments'])
        
        print(f"\nğŸ”§ æ‰§è¡Œå·¥å…·: {tool_name}")
        print(f"   å‚æ•°: {tool_args}")
        tools_used.append(tool_name)
        
        # 4. æ‰§è¡Œå·¥å…·
        tool_result = await tool_registry.execute_tool(tool_name, **tool_args)
        
        # ========== æ™ºèƒ½åå¤„ç† ==========
        if tool_result.success:
            user_query = self._extract_user_query(messages)
            tool_result = await self.tool_postprocessor.process(
                tool_name=tool_name,
                result=tool_result,
                user_query=user_query,
                context=context
            )
        
        # 5. æ·»åŠ åˆ°æ¶ˆæ¯å†å²
        messages.append({
            "role": "assistant",
            "content": None,
            "function_call": function_call
        })
        messages.append({
            "role": "function",
            "name": tool_name,
            "content": str(tool_result.content)
        })
    
    # è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°
    return "è¾¾åˆ°æœ€å¤§å·¥å…·è°ƒç”¨è¿­ä»£æ¬¡æ•°", tools_used
```

**å¾ªç¯é€»è¾‘**:
```
å¼€å§‹
  â†“
è°ƒç”¨LLMï¼ˆå¸¦functionsï¼‰
  â†“
æ£€æŸ¥function_call
  â”œâ”€ æ—  â†’ è¿”å›æœ€ç»ˆå“åº” âœ“
  â””â”€ æœ‰ â†’ ç»§ç»­
      â†“
  æ‰§è¡Œå·¥å…·
      â†“
  æ™ºèƒ½åå¤„ç†ï¼ˆæ–°å¢ï¼‰
      â†“
  æ·»åŠ åˆ°æ¶ˆæ¯å†å²
      â†“
  iteration++
      â†“
  æ£€æŸ¥æ˜¯å¦è¾¾åˆ°max_iterations
      â”œâ”€ æ˜¯ â†’ è¿”å›ï¼ˆå¯èƒ½æœªå®Œæˆï¼‰
      â””â”€ å¦ â†’ å›åˆ°"è°ƒç”¨LLM"
```

---

#### 4.6 è®°å¿†ä¿å­˜

**ä»£ç **:
```python
# 1. ä¿å­˜å¯¹è¯ï¼ˆLLMå±‚è®°å¿†ï¼‰
self.memory.add_conversation(
    session_id,
    user_input,
    response,
    metadata={'agent': self.name}
)

# 2. ä¿å­˜ä»»åŠ¡ï¼ˆAgentå±‚è®°å¿†ï¼‰
self.memory.add_task(user_id, {
    'agent': self.name,
    'input': user_input[:200],
    'result': response[:200],
    'success': True,
    'tools_used': tools_used
})

# 3. å­¦ä¹ ç”¨æˆ·åå¥½
if 'python' in user_input.lower():
    self.memory.remember_preference(user_id, 'preferred_language', 'python')
```

---

### å…³é”®æ–‡ä»¶æ¸…å•

| æ–‡ä»¶ | èŒè´£ | å…³é”®å‡½æ•° |
|------|------|---------|
| `daoyoucode/agents/core/agent.py` | AgentåŸºç±» | `execute()`, `_call_llm_with_tools()` |
| `daoyoucode/agents/builtin/main_agent.py` | MainAgent | ç»§æ‰¿BaseAgent |
| `daoyoucode/agents/memory/__init__.py` | Memoryç®¡ç†å™¨ | `get_memory_manager()` |
| `daoyoucode/agents/tools/postprocessor.py` | å·¥å…·åå¤„ç†å™¨ | `process()` |

---

### ä¾èµ–å…³ç³»

```
agent.py (BaseAgent)
    â†“
â”œâ”€ memory/ (è®°å¿†ç³»ç»Ÿ)
â”‚   â”œâ”€ get_conversation_history()
â”‚   â”œâ”€ get_preferences()
â”‚   â””â”€ add_conversation()
â”œâ”€ tools/ (å·¥å…·ç³»ç»Ÿ)
â”‚   â”œâ”€ get_tool_registry()
â”‚   â””â”€ execute_tool()
â”œâ”€ tools/postprocessor.py (åå¤„ç†)
â”‚   â””â”€ process()
â””â”€ llm/ (LLMå®¢æˆ·ç«¯)
    â””â”€ get_client_manager()
```

---

### ä¸‹ä¸€æ­¥

Agentå±‚å®Œæˆåï¼Œæ§åˆ¶æƒè½¬ç§»åˆ° **å·¥å…·å±‚** æˆ– **LLMå±‚**

â†’ ç»§ç»­é˜…è¯» `CALL_CHAIN_05_TOOL.md` (å·¥å…·è°ƒç”¨)
â†’ æˆ– `CALL_CHAIN_06_LLM.md` (LLMè°ƒç”¨)
