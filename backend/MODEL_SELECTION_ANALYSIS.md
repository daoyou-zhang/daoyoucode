# 模型选择分析

## 问题场景

用户询问：搜索失败时AI判断不准确，是否应该换成 code 模型？

**具体问题**：
```
AI: text_search(query="timeout") → 没结果
AI: "代码库中没有超时处理逻辑"
实际：代码已经存在，只是搜索失败了
```

---

## 根本原因分析

### 1. 搜索失败的原因
- 可能是索引问题（text_search 依赖代码索引）
- 可能是搜索词不匹配（timeout vs 超时 vs TimeoutError）
- 可能是文件路径问题

### 2. 推理不足的原因
- 模型在单次搜索失败后没有尝试其他方法
- 缺乏"验证"意识（一次失败就断定不存在）
- Prompt 没有明确要求多重验证

### 3. 这不是代码生成问题
- 问题在于：搜索策略、推理验证、上下文理解
- 不是代码质量或语法问题
- Code 模型在这些方面不一定更好

---

## 模型对比

### qwen-plus（当前使用）
**优势**：
- 通用能力强，适合 Agent 场景
- 理解力好，能理解复杂指令
- 推理能力不错
- 成本适中（性价比高）

**劣势**：
- 代码生成可能不如专业模型
- 推理深度可能不如 qwen-max

**适用场景**：
- 对话式交互
- 任务规划
- 工具调用
- 通用编程任务

### qwen-coder（代码专用）
**优势**：
- 代码生成质量高
- 语法准确性好
- 代码补全能力强

**劣势**：
- 推理能力可能较弱
- 对话不够自然
- 任务规划能力可能不足
- 工具调用理解可能不如通用模型

**适用场景**：
- 纯代码生成
- 代码补全
- 语法修复

### qwen-max（最强模型）
**优势**：
- 最强推理能力
- 最好的理解力
- 最好的任务规划
- 最好的工具调用

**劣势**：
- 成本高（约 qwen-plus 的 2-3 倍）

**适用场景**：
- 复杂任务
- 需要深度推理
- 关键业务场景

---

## 建议

### ❌ 不建议换成 code 模型

**原因**：
1. 当前问题不是代码生成问题
2. Code 模型的推理能力可能更弱
3. Agent 场景需要通用能力，不只是代码生成

### ✅ 推荐方案

#### 方案1: 优化 Prompt（已完成）
- ✅ 添加上下文检查
- ✅ 添加搜索备选方案
- ✅ 强化推理要求
- ✅ 添加验证机制

**效果**：
- 成本：0
- 提升：显著（prompt 是最重要的）

#### 方案2: 升级到 qwen-max（推荐）
```yaml
default:
  model: qwen-max  # 最强推理能力
```

**效果**：
- 成本：+100-200%
- 提升：推理能力 +30-50%
- 适合：对质量要求高的场景

#### 方案3: 混合策略（最优）
```yaml
# 简单任务用 qwen-plus
# 复杂任务用 qwen-max
# 根据任务类型动态选择
```

**实现**：
- 在 skill 配置中指定模型
- 或在 context 中传递 model 参数

---

## 成本对比

假设每天 100 次调用，每次 2000 tokens：

| 模型 | 单价 | 日成本 | 月成本 | 推理能力 |
|------|------|--------|--------|----------|
| qwen-turbo | 最低 | ¥1-2 | ¥30-60 | ⭐⭐ |
| qwen-plus | 中等 | ¥3-5 | ¥90-150 | ⭐⭐⭐ |
| qwen-max | 最高 | ¥8-12 | ¥240-360 | ⭐⭐⭐⭐⭐ |
| qwen-coder | 中等 | ¥3-5 | ¥90-150 | ⭐⭐⭐（代码）|

---

## 实际测试建议

### 测试场景1: 搜索失败处理
```
用户: "看看有没有超时处理"
期望: 
1. text_search("timeout")
2. 如果失败 → text_search("超时")
3. 如果失败 → list_files("**/timeout*.py")
4. 如果失败 → get_repo_structure
5. 综合判断
```

### 测试场景2: 上下文理解
```
用户: "继续实现"
期望: 检查对话历史，理解"继续"的含义
```

### 测试场景3: 复杂推理
```
用户: "优化这个模块的性能"
期望: 
1. 理解模块功能
2. 分析性能瓶颈
3. 提出优化方案
4. 评估影响
```

**测试方法**：
1. 用 qwen-plus 测试（当前）
2. 用 qwen-max 测试（对比）
3. 用 qwen-coder 测试（对比）
4. 对比结果

---

## 结论

### 短期（立即）
- ✅ 使用优化后的 prompt
- ✅ 保持 qwen-plus（性价比高）
- ✅ 观察效果

### 中期（1-2周）
- 🔄 如果效果不理想，升级到 qwen-max
- 🔄 测试不同场景的表现
- 🔄 评估成本收益

### 长期（1-2月）
- 🎯 实现混合策略（简单任务用 plus，复杂任务用 max）
- 🎯 根据任务类型自动选择模型
- 🎯 持续优化 prompt

---

## 配置建议

### 当前配置（性价比）
```yaml
default:
  model: qwen-plus
```

### 推荐配置（质量优先）
```yaml
default:
  model: qwen-max
fallback:
  chains:
    qwen-max:
      - qwen-plus
      - qwen-turbo
```

### 未来配置（智能选择）
```yaml
# 在 skill 中指定
chat-assistant:
  model: qwen-max  # 复杂对话用 max

code-generation:
  model: qwen-coder  # 代码生成用 coder

simple-query:
  model: qwen-plus  # 简单查询用 plus
```

---

## 总结

**不要换成 code 模型**，因为：
1. 当前问题是推理和策略问题，不是代码生成问题
2. Prompt 优化已经解决了大部分问题
3. 如果还不够，升级到 qwen-max 比换 code 模型更好
4. Agent 场景需要通用能力，code 模型可能反而更差

**最佳实践**：
- Prompt 优化 > 模型选择
- 通用模型 > 专用模型（对于 Agent）
- qwen-max > qwen-coder（对于推理任务）
