"""
å‘é‡æ£€ç´¢å™¨ï¼ˆå¯é€‰åŠŸèƒ½ï¼‰

ä½¿ç”¨embeddingè¿›è¡Œè¯­ä¹‰ç›¸ä¼¼åº¦åŒ¹é…ï¼Œæ¯”å…³é”®è¯åŒ¹é…æ›´ç²¾å‡†

ä¾èµ–ï¼š
- sentence-transformersï¼ˆå¯é€‰ï¼Œéœ€è¦æ‰‹åŠ¨å®‰è£…ï¼‰
- numpy

å®‰è£…ï¼š
pip install sentence-transformers

å¦‚æœä¸å®‰è£…ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨é™çº§åˆ°å…³é”®è¯åŒ¹é…ï¼Œä¸å½±å“åŠŸèƒ½ã€‚
"""

from typing import List, Dict, Tuple, Optional
import logging

logger = logging.getLogger(__name__)


class VectorRetriever:
    """
    å‘é‡æ£€ç´¢å™¨ï¼ˆå¯é€‰ï¼‰
    
    åŠŸèƒ½ï¼š
    1. å°†æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡ï¼ˆembeddingï¼‰
    2. è®¡ç®—å‘é‡ç›¸ä¼¼åº¦ï¼ˆä½™å¼¦ç›¸ä¼¼åº¦ï¼‰
    3. æ£€ç´¢æœ€ç›¸å…³çš„å†å²å¯¹è¯
    
    ä¼˜åŠ¿ï¼š
    - è¯­ä¹‰åŒ¹é…ï¼šç†è§£"çŒ«å’ª"å’Œ"å°çŒ«"æ˜¯åŒä¸€ä¸ªæ„æ€
    - æ›´å‡†ç¡®ï¼šæ¯”å…³é”®è¯åŒ¹é…å‡†ç¡®ç‡é«˜10-20%
    - è·¨è¯­è¨€ï¼šæ”¯æŒå¤šè¯­è¨€ï¼ˆå¦‚æœä½¿ç”¨å¤šè¯­è¨€æ¨¡å‹ï¼‰
    
    æ³¨æ„ï¼š
    - é»˜è®¤ç¦ç”¨ï¼ˆenabled=Falseï¼‰
    - éœ€è¦æ‰‹åŠ¨å®‰è£… sentence-transformers
    - å¦‚æœä¸å®‰è£…ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨é™çº§åˆ°å…³é”®è¯åŒ¹é…
    """
    
    def __init__(self, model_name: str = "paraphrase-multilingual-MiniLM-L12-v2"):
        """
        åˆå§‹åŒ–å‘é‡æ£€ç´¢å™¨
        
        Args:
            model_name: embeddingæ¨¡å‹åç§°
                - paraphrase-multilingual-MiniLM-L12-v2: å¤šè¯­è¨€ï¼Œ384ç»´ï¼Œ50MB
                - all-MiniLM-L6-v2: è‹±æ–‡ï¼Œ384ç»´ï¼Œ80MB
                - text2vec-base-chinese: ä¸­æ–‡ï¼Œ768ç»´ï¼Œ400MB
        """
        self.model_name = model_name
        self.model = None
        self.enabled = False
        
        # å°è¯•åŠ è½½æ¨¡å‹ï¼ˆé»˜è®¤ä¸åŠ è½½ï¼‰
        # self._load_model()  # â† æ³¨é‡Šæ‰ï¼Œé»˜è®¤ç¦ç”¨
        
        logger.info("å‘é‡æ£€ç´¢å™¨å·²åˆå§‹åŒ–ï¼ˆé»˜è®¤ç¦ç”¨ï¼‰")
        logger.info("ğŸ’¡ è¦å¯ç”¨å‘é‡æ£€ç´¢ï¼Œè¯·å®‰è£…: pip install sentence-transformers")
    
    def _load_model(self):
        """åŠ è½½embeddingæ¨¡å‹"""
        try:
            from sentence_transformers import SentenceTransformer
            
            logger.info(f"ğŸ”„ åŠ è½½embeddingæ¨¡å‹: {self.model_name}")
            self.model = SentenceTransformer(self.model_name)
            self.enabled = True
            logger.info(f"âœ… å‘é‡æ£€ç´¢å·²å¯ç”¨: {self.model_name}")
        
        except ImportError:
            logger.info(
                "â„¹ï¸ sentence-transformersæœªå®‰è£…ï¼Œå‘é‡æ£€ç´¢ä¸å¯ç”¨\n"
                "ğŸ’¡ å®‰è£…: pip install sentence-transformers"
            )
            self.enabled = False
        
        except Exception as e:
            logger.warning(f"âš ï¸ åŠ è½½embeddingæ¨¡å‹å¤±è´¥: {e}")
            self.enabled = False
    
    def enable(self):
        """æ‰‹åŠ¨å¯ç”¨å‘é‡æ£€ç´¢"""
        if not self.enabled:
            self._load_model()
    
    def encode(self, text: str) -> Optional['numpy.ndarray']:
        """
        å°†æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡
        
        Args:
            text: æ–‡æœ¬
        
        Returns:
            å‘é‡ï¼ˆnumpyæ•°ç»„ï¼‰ï¼Œå¦‚æœå¤±è´¥è¿”å›None
        """
        if not self.enabled or not self.model:
            return None
        
        try:
            # è½¬æ¢ä¸ºå‘é‡
            embedding = self.model.encode(text, convert_to_numpy=True)
            return embedding
        
        except Exception as e:
            logger.error(f"âŒ æ–‡æœ¬ç¼–ç å¤±è´¥: {e}")
            return None
    
    def cosine_similarity(self, vec1, vec2) -> float:
        """
        è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
        
        Args:
            vec1: å‘é‡1
            vec2: å‘é‡2
        
        Returns:
            ç›¸ä¼¼åº¦åˆ†æ•°ï¼ˆ0-1ï¼‰
        """
        try:
            import numpy as np
            
            # å½’ä¸€åŒ–
            vec1_norm = vec1 / np.linalg.norm(vec1)
            vec2_norm = vec2 / np.linalg.norm(vec2)
            
            # ä½™å¼¦ç›¸ä¼¼åº¦
            similarity = np.dot(vec1_norm, vec2_norm)
            
            return float(similarity)
        except Exception as e:
            logger.error(f"âŒ è®¡ç®—ç›¸ä¼¼åº¦å¤±è´¥: {e}")
            return 0.0
    
    async def find_relevant_history(
        self,
        current_message: str,
        full_history: List[Dict],
        limit: int = 3,
        threshold: float = 0.5
    ) -> List[Tuple[int, float]]:
        """
        ä½¿ç”¨å‘é‡æ£€ç´¢æŸ¥æ‰¾ç›¸å…³å†å²
        
        Args:
            current_message: å½“å‰æ¶ˆæ¯
            full_history: å®Œæ•´å†å²
            limit: æœ€å¤šè¿”å›å¤šå°‘æ¡
            threshold: ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆ0-1ï¼‰
        
        Returns:
            [(ç´¢å¼•, ç›¸ä¼¼åº¦åˆ†æ•°), ...]
        """
        if not self.enabled:
            logger.debug("å‘é‡æ£€ç´¢æœªå¯ç”¨ï¼Œè¿”å›ç©ºç»“æœ")
            return []
        
        try:
            # 1. ç¼–ç å½“å‰æ¶ˆæ¯
            current_embedding = self.encode(current_message)
            if current_embedding is None:
                return []
            
            # 2. ç¼–ç æ‰€æœ‰å†å²æ¶ˆæ¯å¹¶è®¡ç®—ç›¸ä¼¼åº¦
            similarities = []
            
            for idx, item in enumerate(full_history):
                user_msg = item.get('user', '')
                if not user_msg:
                    continue
                
                # ç¼–ç å†å²æ¶ˆæ¯
                msg_embedding = self.encode(user_msg)
                if msg_embedding is None:
                    continue
                
                # è®¡ç®—ç›¸ä¼¼åº¦
                similarity = self.cosine_similarity(current_embedding, msg_embedding)
                
                # åªä¿ç•™è¶…è¿‡é˜ˆå€¼çš„
                if similarity >= threshold:
                    similarities.append((idx, similarity))
                    logger.debug(
                        f"  ğŸ¯ å‘é‡åŒ¹é…ç¬¬{idx+1}è½®: {user_msg[:30]}... "
                        f"(ç›¸ä¼¼åº¦: {similarity:.3f})"
                    )
            
            # 3. æŒ‰ç›¸ä¼¼åº¦æ’åºï¼Œè¿”å›top N
            similarities.sort(key=lambda x: x[1], reverse=True)
            return similarities[:limit]
        
        except Exception as e:
            logger.error(f"âŒ å‘é‡æ£€ç´¢å¤±è´¥: {e}", exc_info=True)
            return []
    
    def get_stats(self) -> Dict:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        stats = {
            'enabled': self.enabled,
            'model_name': self.model_name if self.enabled else None,
        }
        
        if self.enabled and self.model:
            try:
                stats['embedding_dim'] = self.model.get_sentence_embedding_dimension()
            except:
                pass
        
        return stats


# å…¨å±€å•ä¾‹
_vector_retriever = None

def get_vector_retriever(model_name: str = "paraphrase-multilingual-MiniLM-L12-v2") -> VectorRetriever:
    """è·å–å‘é‡æ£€ç´¢å™¨å•ä¾‹"""
    global _vector_retriever
    if _vector_retriever is None:
        _vector_retriever = VectorRetriever(model_name)
    return _vector_retriever
