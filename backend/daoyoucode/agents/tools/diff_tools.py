"""
Diffå·¥å…· - æ™ºèƒ½æ›¿æ¢ç­–ç•¥

é‡‡ç”¨å…ˆè¿›çš„ Diff ç³»ç»Ÿå®ç°ï¼Œæ”¯æŒï¼š
- 9ç§æ™ºèƒ½æ›¿æ¢ç­–ç•¥
- Levenshteinè·ç¦»ç®—æ³•
- BlockAnchorReplacerï¼ˆé¦–å°¾è¡Œé”šå®šï¼‰
- æ¨¡ç³ŠåŒ¹é…å’Œå®¹é”™
"""

from typing import Dict, Any, Generator, Optional, List, Tuple
from pathlib import Path
import re
from .base import BaseTool, ToolResult


# ========== Levenshteinè·ç¦»ç®—æ³• ==========

def levenshtein(a: str, b: str) -> int:
    """
    è®¡ç®—ä¸¤ä¸ªå­—ç¬¦ä¸²çš„Levenshteinç¼–è¾‘è·ç¦»
    
    ç”¨äºè¡¡é‡å­—ç¬¦ä¸²ç›¸ä¼¼åº¦ï¼Œè·ç¦»è¶Šå°è¶Šç›¸ä¼¼
    """
    if a == "" or b == "":
        return max(len(a), len(b))
    
    # åˆ›å»ºè·ç¦»çŸ©é˜µ
    matrix = [[0] * (len(b) + 1) for _ in range(len(a) + 1)]
    
    # åˆå§‹åŒ–ç¬¬ä¸€è¡Œå’Œç¬¬ä¸€åˆ—
    for i in range(len(a) + 1):
        matrix[i][0] = i
    for j in range(len(b) + 1):
        matrix[0][j] = j
    
    # åŠ¨æ€è§„åˆ’è®¡ç®—è·ç¦»
    for i in range(1, len(a) + 1):
        for j in range(1, len(b) + 1):
            cost = 0 if a[i - 1] == b[j - 1] else 1
            matrix[i][j] = min(
                matrix[i - 1][j] + 1,      # åˆ é™¤
                matrix[i][j - 1] + 1,      # æ’å…¥
                matrix[i - 1][j - 1] + cost  # æ›¿æ¢
            )
    
    return matrix[len(a)][len(b)]


# ========== 9ç§Replacerç­–ç•¥ ==========

class Replacer:
    """ReplaceråŸºç±»"""
    
    @staticmethod
    def find_matches(content: str, find: str) -> Generator[str, None, None]:
        """æŸ¥æ‰¾æ‰€æœ‰åŒ¹é…é¡¹"""
        raise NotImplementedError()


class SimpleReplacer(Replacer):
    """ç­–ç•¥1: ç²¾ç¡®åŒ¹é…"""
    
    @staticmethod
    def find_matches(content: str, find: str) -> Generator[str, None, None]:
        if find in content:
            yield find


class LineTrimmedReplacer(Replacer):
    """ç­–ç•¥2: å¿½ç•¥è¡Œé¦–å°¾ç©ºç™½"""
    
    @staticmethod
    def find_matches(content: str, find: str) -> Generator[str, None, None]:
        original_lines = content.split("\n")
        search_lines = find.split("\n")
        
        # ç§»é™¤æœ«å°¾ç©ºè¡Œ
        if search_lines and search_lines[-1] == "":
            search_lines.pop()
        
        # æ»‘åŠ¨çª—å£åŒ¹é…
        for i in range(len(original_lines) - len(search_lines) + 1):
            matches = True
            
            for j in range(len(search_lines)):
                if original_lines[i + j].strip() != search_lines[j].strip():
                    matches = False
                    break
            
            if matches:
                # è®¡ç®—åŒ¹é…çš„èµ·æ­¢ä½ç½®
                match_start = sum(len(original_lines[k]) + 1 for k in range(i))
                match_end = match_start + sum(
                    len(original_lines[i + k]) + (1 if k < len(search_lines) - 1 else 0)
                    for k in range(len(search_lines))
                )
                yield content[match_start:match_end]


class BlockAnchorReplacer(Replacer):
    """
    ç­–ç•¥3: é¦–å°¾è¡Œé”šå®š + Levenshteinç›¸ä¼¼åº¦
    
    è¿™æ˜¯æœ€å¼ºå¤§çš„ç­–ç•¥ï¼š
    - ä½¿ç”¨é¦–å°¾è¡Œä½œä¸ºé”šç‚¹
    - è®¡ç®—ä¸­é—´è¡Œçš„Levenshteinç›¸ä¼¼åº¦
    - å•å€™é€‰é˜ˆå€¼0.0ï¼Œå¤šå€™é€‰é˜ˆå€¼0.3
    """
    
    SINGLE_CANDIDATE_THRESHOLD = 0.0
    MULTIPLE_CANDIDATES_THRESHOLD = 0.3
    
    @staticmethod
    def find_matches(content: str, find: str) -> Generator[str, None, None]:
        original_lines = content.split("\n")
        search_lines = find.split("\n")
        
        if len(search_lines) < 3:
            return
        
        if search_lines and search_lines[-1] == "":
            search_lines.pop()
        
        first_line = search_lines[0].strip()
        last_line = search_lines[-1].strip()
        search_block_size = len(search_lines)
        
        # æ”¶é›†æ‰€æœ‰å€™é€‰ä½ç½®
        candidates: List[Tuple[int, int]] = []
        for i in range(len(original_lines)):
            if original_lines[i].strip() != first_line:
                continue
            
            # æŸ¥æ‰¾åŒ¹é…çš„æœ«å°¾è¡Œ
            for j in range(i + 2, len(original_lines)):
                if original_lines[j].strip() == last_line:
                    candidates.append((i, j))
                    break
        
        if not candidates:
            return
        
        # å•å€™é€‰æƒ…å†µï¼ˆä½¿ç”¨å®½æ¾é˜ˆå€¼ï¼‰
        if len(candidates) == 1:
            start_line, end_line = candidates[0]
            actual_block_size = end_line - start_line + 1
            
            similarity = 0.0
            lines_to_check = min(search_block_size - 2, actual_block_size - 2)
            
            if lines_to_check > 0:
                for j in range(1, min(search_block_size - 1, actual_block_size - 1)):
                    original_line = original_lines[start_line + j].strip()
                    search_line = search_lines[j].strip()
                    max_len = max(len(original_line), len(search_line))
                    
                    if max_len == 0:
                        continue
                    
                    distance = levenshtein(original_line, search_line)
                    similarity += (1 - distance / max_len) / lines_to_check
                    
                    if similarity >= BlockAnchorReplacer.SINGLE_CANDIDATE_THRESHOLD:
                        break
            else:
                similarity = 1.0
            
            if similarity >= BlockAnchorReplacer.SINGLE_CANDIDATE_THRESHOLD:
                match_start = sum(len(original_lines[k]) + 1 for k in range(start_line))
                match_end = match_start + sum(
                    len(original_lines[k]) + (1 if k < end_line else 0)
                    for k in range(start_line, end_line + 1)
                )
                yield content[match_start:match_end]
            return
        
        # å¤šå€™é€‰æƒ…å†µï¼ˆè®¡ç®—æœ€ä½³åŒ¹é…ï¼‰
        best_match: Optional[Tuple[int, int]] = None
        max_similarity = -1.0
        
        for start_line, end_line in candidates:
            actual_block_size = end_line - start_line + 1
            
            similarity = 0.0
            lines_to_check = min(search_block_size - 2, actual_block_size - 2)
            
            if lines_to_check > 0:
                for j in range(1, min(search_block_size - 1, actual_block_size - 1)):
                    original_line = original_lines[start_line + j].strip()
                    search_line = search_lines[j].strip()
                    max_len = max(len(original_line), len(search_line))
                    
                    if max_len == 0:
                        continue
                    
                    distance = levenshtein(original_line, search_line)
                    similarity += 1 - distance / max_len
                
                similarity /= lines_to_check
            else:
                similarity = 1.0
            
            if similarity > max_similarity:
                max_similarity = similarity
                best_match = (start_line, end_line)
        
        if max_similarity >= BlockAnchorReplacer.MULTIPLE_CANDIDATES_THRESHOLD and best_match:
            start_line, end_line = best_match
            match_start = sum(len(original_lines[k]) + 1 for k in range(start_line))
            match_end = match_start + sum(
                len(original_lines[k]) + (1 if k < end_line else 0)
                for k in range(start_line, end_line + 1)
            )
            yield content[match_start:match_end]


class WhitespaceNormalizedReplacer(Replacer):
    """ç­–ç•¥4: ç©ºç™½å½’ä¸€åŒ–"""
    
    @staticmethod
    def normalize_whitespace(text: str) -> str:
        return re.sub(r'\s+', ' ', text).strip()
    
    @staticmethod
    def find_matches(content: str, find: str) -> Generator[str, None, None]:
        normalized_find = WhitespaceNormalizedReplacer.normalize_whitespace(find)
        
        # å•è¡ŒåŒ¹é…
        lines = content.split("\n")
        for line in lines:
            if WhitespaceNormalizedReplacer.normalize_whitespace(line) == normalized_find:
                yield line
        
        # å¤šè¡ŒåŒ¹é…
        find_lines = find.split("\n")
        if len(find_lines) > 1:
            for i in range(len(lines) - len(find_lines) + 1):
                block = "\n".join(lines[i:i + len(find_lines)])
                if WhitespaceNormalizedReplacer.normalize_whitespace(block) == normalized_find:
                    yield block


class IndentationFlexibleReplacer(Replacer):
    """ç­–ç•¥5: ç¼©è¿›çµæ´»åŒ¹é…"""
    
    @staticmethod
    def remove_indentation(text: str) -> str:
        lines = text.split("\n")
        non_empty_lines = [line for line in lines if line.strip()]
        
        if not non_empty_lines:
            return text
        
        min_indent = min(
            len(line) - len(line.lstrip())
            for line in non_empty_lines
        )
        
        return "\n".join(
            line[min_indent:] if line.strip() else line
            for line in lines
        )
    
    @staticmethod
    def find_matches(content: str, find: str) -> Generator[str, None, None]:
        normalized_find = IndentationFlexibleReplacer.remove_indentation(find)
        content_lines = content.split("\n")
        find_lines = find.split("\n")
        
        for i in range(len(content_lines) - len(find_lines) + 1):
            block = "\n".join(content_lines[i:i + len(find_lines)])
            if IndentationFlexibleReplacer.remove_indentation(block) == normalized_find:
                yield block


class EscapeNormalizedReplacer(Replacer):
    """ç­–ç•¥6: è½¬ä¹‰å­—ç¬¦å¤„ç†"""
    
    @staticmethod
    def unescape_string(s: str) -> str:
        replacements = {
            r'\n': '\n',
            r'\t': '\t',
            r'\r': '\r',
            r"\'": "'",
            r'\"': '"',
            r'\`': '`',
            r'\\': '\\',
            r'\$': '$',
        }
        result = s
        for escaped, unescaped in replacements.items():
            result = result.replace(escaped, unescaped)
        return result
    
    @staticmethod
    def find_matches(content: str, find: str) -> Generator[str, None, None]:
        unescaped_find = EscapeNormalizedReplacer.unescape_string(find)
        
        if unescaped_find in content:
            yield unescaped_find
        
        # å°è¯•æŸ¥æ‰¾è½¬ä¹‰ç‰ˆæœ¬
        lines = content.split("\n")
        find_lines = unescaped_find.split("\n")
        
        for i in range(len(lines) - len(find_lines) + 1):
            block = "\n".join(lines[i:i + len(find_lines)])
            if EscapeNormalizedReplacer.unescape_string(block) == unescaped_find:
                yield block


class TrimmedBoundaryReplacer(Replacer):
    """ç­–ç•¥7: è¾¹ç•Œtrim"""
    
    @staticmethod
    def find_matches(content: str, find: str) -> Generator[str, None, None]:
        trimmed_find = find.strip()
        
        if trimmed_find == find:
            return
        
        if trimmed_find in content:
            yield trimmed_find
        
        lines = content.split("\n")
        find_lines = find.split("\n")
        
        for i in range(len(lines) - len(find_lines) + 1):
            block = "\n".join(lines[i:i + len(find_lines)])
            if block.strip() == trimmed_find:
                yield block


class ContextAwareReplacer(Replacer):
    """ç­–ç•¥8: ä¸Šä¸‹æ–‡æ„ŸçŸ¥"""
    
    @staticmethod
    def find_matches(content: str, find: str) -> Generator[str, None, None]:
        find_lines = find.split("\n")
        if len(find_lines) < 3:
            return
        
        if find_lines and find_lines[-1] == "":
            find_lines.pop()
        
        content_lines = content.split("\n")
        first_line = find_lines[0].strip()
        last_line = find_lines[-1].strip()
        
        for i in range(len(content_lines)):
            if content_lines[i].strip() != first_line:
                continue
            
            for j in range(i + 2, len(content_lines)):
                if content_lines[j].strip() == last_line:
                    block_lines = content_lines[i:j + 1]
                    
                    if len(block_lines) == len(find_lines):
                        # æ£€æŸ¥ä¸­é—´è¡Œç›¸ä¼¼åº¦ï¼ˆè‡³å°‘50%åŒ¹é…ï¼‰
                        matching_lines = 0
                        total_non_empty = 0
                        
                        for k in range(1, len(block_lines) - 1):
                            block_line = block_lines[k].strip()
                            find_line = find_lines[k].strip()
                            
                            if block_line or find_line:
                                total_non_empty += 1
                                if block_line == find_line:
                                    matching_lines += 1
                        
                        if total_non_empty == 0 or matching_lines / total_non_empty >= 0.5:
                            yield "\n".join(block_lines)
                            break
                    break


class MultiOccurrenceReplacer(Replacer):
    """ç­–ç•¥9: å¤šæ¬¡å‡ºç°å¤„ç†"""
    
    @staticmethod
    def find_matches(content: str, find: str) -> Generator[str, None, None]:
        start_index = 0
        while True:
            index = content.find(find, start_index)
            if index == -1:
                break
            yield find
            start_index = index + len(find)


# ========== æ ¸å¿ƒæ›¿æ¢å‡½æ•° ==========

def replace(content: str, old_string: str, new_string: str, replace_all: bool = False) -> str:
    """
    ä½¿ç”¨9ç§ç­–ç•¥è¿›è¡Œæ™ºèƒ½æ›¿æ¢
    
    Args:
        content: åŸå§‹å†…å®¹
        old_string: è¦æ›¿æ¢çš„å­—ç¬¦ä¸²
        new_string: æ›¿æ¢åçš„å­—ç¬¦ä¸²
        replace_all: æ˜¯å¦æ›¿æ¢æ‰€æœ‰å‡ºç°
    
    Returns:
        æ›¿æ¢åçš„å†…å®¹
    
    Raises:
        ValueError: å¦‚æœæ‰¾ä¸åˆ°åŒ¹é…æˆ–æœ‰å¤šä¸ªåŒ¹é…
    """
    if old_string == new_string:
        raise ValueError("old_string and new_string must be different")
    
    not_found = True
    
    # æŒ‰ä¼˜å…ˆçº§å°è¯•9ç§ç­–ç•¥
    replacers = [
        SimpleReplacer,
        LineTrimmedReplacer,
        BlockAnchorReplacer,
        WhitespaceNormalizedReplacer,
        IndentationFlexibleReplacer,
        EscapeNormalizedReplacer,
        TrimmedBoundaryReplacer,
        ContextAwareReplacer,
        MultiOccurrenceReplacer,
    ]
    
    for replacer_class in replacers:
        for search in replacer_class.find_matches(content, old_string):
            index = content.find(search)
            if index == -1:
                continue
            
            not_found = False
            
            if replace_all:
                return content.replace(search, new_string)
            
            # æ£€æŸ¥æ˜¯å¦å”¯ä¸€
            last_index = content.rfind(search)
            if index != last_index:
                continue
            
            # æ‰§è¡Œæ›¿æ¢
            return content[:index] + new_string + content[index + len(search):]
    
    if not_found:
        raise ValueError("old_string not found in content")
    
    raise ValueError(
        "Found multiple matches for old_string. "
        "Provide more surrounding lines to identify the correct match."
    )


# ========== å·¥å…·å°è£… ==========

class SearchReplaceTool(BaseTool):
    """SEARCH/REPLACEç¼–è¾‘å·¥å…·"""
    
    def __init__(self):
        super().__init__(
            name="search_replace",
            description="ä½¿ç”¨SEARCH/REPLACEæ¨¡å¼ç¼–è¾‘æ–‡ä»¶ï¼ˆæ”¯æŒ9ç§æ™ºèƒ½åŒ¹é…ç­–ç•¥ï¼‰"
        )
    
    async def execute(
        self,
        file_path: str,
        search: str,
        replace: str,
        replace_all: bool = False
    ) -> ToolResult:
        """
        æ‰§è¡ŒSEARCH/REPLACE
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            search: è¦æœç´¢çš„å†…å®¹
            replace: æ›¿æ¢åçš„å†…å®¹
            replace_all: æ˜¯å¦æ›¿æ¢æ‰€æœ‰å‡ºç°
        """
        try:
            # ä½¿ç”¨ resolve_path è§£æè·¯å¾„
            path = self.resolve_path(file_path)
            
            if not path.exists():
                return ToolResult(
                    success=False,
                    content=None,
                    error=f"File not found: {file_path} (resolved to {path})"
                )
            
            # è¯»å–åŸå§‹æ–‡ä»¶å†…å®¹
            old_content = path.read_text(encoding='utf-8', errors='ignore')
            
            # æ‰§è¡Œæ›¿æ¢ï¼ˆä½¿ç”¨æ¨¡å—çº§å‡½æ•°ï¼‰
            from . import diff_tools
            new_content = diff_tools.replace(old_content, search, replace, replace_all)
            
            # ç”Ÿæˆ diff
            import difflib
            diff_lines = list(difflib.unified_diff(
                old_content.splitlines(keepends=True),
                new_content.splitlines(keepends=True),
                fromfile=f"a/{file_path}",
                tofile=f"b/{file_path}",
                lineterm=''
            ))
            
            diff_text = ''.join(diff_lines) if diff_lines else "No changes"
            
            # å†™å…¥æ–‡ä»¶
            path.write_text(new_content, encoding='utf-8')
            
            # æ„å»ºç»“æœæ¶ˆæ¯
            result_message = f"âœ… Successfully modified {file_path}\n\n"
            result_message += "ğŸ“ Changes:\n"
            result_message += "```diff\n"
            result_message += diff_text
            result_message += "\n```"
            
            return ToolResult(
                success=True,
                content=result_message,
                metadata={
                    'file_path': str(path),
                    'old_size': len(old_content),
                    'new_size': len(new_content),
                    'replace_all': replace_all,
                    'diff': diff_text,
                    'changes_count': len([line for line in diff_lines if line.startswith('+') or line.startswith('-')])
                }
            )
        except Exception as e:
            return ToolResult(
                success=False,
                content=None,
                error=str(e)
            )
    
    def get_function_schema(self) -> Dict[str, Any]:
        return {
            "name": self.name,
            "description": self.description,
            "parameters": {
                "type": "object",
                "properties": {
                    "file_path": {
                        "type": "string",
                        "description": "æ–‡ä»¶è·¯å¾„"
                    },
                    "search": {
                        "type": "string",
                        "description": "è¦æœç´¢çš„å†…å®¹"
                    },
                    "replace": {
                        "type": "string",
                        "description": "æ›¿æ¢åçš„å†…å®¹"
                    },
                    "replace_all": {
                        "type": "boolean",
                        "description": "æ˜¯å¦æ›¿æ¢æ‰€æœ‰å‡ºç°",
                        "default": False
                    }
                },
                "required": ["file_path", "search", "replace"]
            }
        }


# ========== Unified Diff (editblock/udiff å¼ç»†ç²’åº¦ç¼–è¾‘) ==========

def _parse_unified_diff(diff_text: str) -> List[Dict[str, Any]]:
    """
    è§£æ unified diffï¼Œè¿”å› [{"path": str, "hunks": [(old_start, old_count, new_start, new_count, lines)]}, ...]
    path ä¸ºç›¸å¯¹è·¯å¾„ï¼ˆå·²å»æ‰ a/ b/ å‰ç¼€ï¼‰
    """
    files = []
    current_file: Optional[Dict[str, Any]] = None
    current_hunk: Optional[Tuple] = None
    for line in diff_text.splitlines(keepends=True):
        if line.startswith("--- "):
            # æ—§æ–‡ä»¶è·¯å¾„ï¼š--- a/foo.py æˆ– --- foo.py
            raw = line[4:].rstrip()
            path = raw.split("\t")[0].strip()
            if path.startswith("a/"):
                path = path[2:]
            if current_file and current_hunk is not None:
                current_file["hunks"].append(current_hunk)
            current_file = {"path": path, "hunks": []}
            current_hunk = None
        elif line.startswith("+++ "):
            # æ–°æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ä½¿ç”¨ï¼‰
            raw = line[4:].rstrip()
            path = raw.split("\t")[0].strip()
            if path.startswith("b/"):
                path = path[2:]
            if current_file:
                current_file["path"] = path
            current_hunk = None
        elif line.startswith("@@ "):
            if current_file is None:
                continue
            if current_hunk is not None:
                current_file["hunks"].append(current_hunk)
            # @@ -old_start,old_count +new_start,new_count @@
            m = re.match(r"@@ -(\d+)(?:,(\d+))? \+(\d+)(?:,(\d+))? @@", line.strip())
            if m:
                old_s, old_c, new_s, new_c = m.groups()
                current_hunk = (
                    int(old_s),
                    int(old_c) if old_c else 1,
                    int(new_s),
                    int(new_c) if new_c else 1,
                    [],
                )
        elif current_hunk is not None:
            # è¡Œå†…å®¹ï¼šç©ºæ ¼=ä¸Šä¸‹æ–‡ï¼Œ-=åˆ é™¤ï¼Œ+=æ·»åŠ 
            current_hunk[4].append(line)
    if current_file and current_hunk is not None:
        current_file["hunks"].append(current_hunk)
    if current_file:
        files.append(current_file)
    return files


def _apply_hunk(old_lines: List[str], old_start: int, old_count: int, new_start: int, new_count: int, hunk_lines: List[str]) -> List[str]:
    """åº”ç”¨å•ä¸ª hunkã€‚old_lines ä¸ºå¸¦æ¢è¡Œç¬¦çš„è¡Œåˆ—è¡¨ï¼›unified diffï¼šç©ºæ ¼=ä¸Šä¸‹æ–‡ï¼Œ-=åˆ é™¤ï¼Œ+=æ·»åŠ ã€‚"""
    if old_start <= 0:
        result = []
        old_pos = 0
    else:
        result = old_lines[: old_start - 1]
        old_pos = old_start - 1
    for hunk_line in hunk_lines:
        if len(hunk_line) < 1:
            continue
        if hunk_line[0] == " ":
            result.append(hunk_line[1:] if hunk_line.endswith("\n") else hunk_line[1:] + "\n")
            old_pos += 1
        elif hunk_line[0] == "-":
            old_pos += 1
        elif hunk_line[0] == "+":
            result.append(hunk_line[1:] if hunk_line.endswith("\n") else hunk_line[1:] + "\n")
    result.extend(old_lines[old_pos:])
    return result


class ApplyPatchTool(BaseTool):
    """
    åº”ç”¨ Unified Diffï¼ˆeditblock/udiff å¼ç»†ç²’åº¦ç¼–è¾‘ï¼‰
    
    æ¥å—æ¨¡å‹è¾“å‡ºçš„æ ‡å‡† unified diff æ–‡æœ¬ï¼ŒæŒ‰ hunk ç²¾ç¡®åº”ç”¨ï¼Œä¾¿äºå®¡è®¡å’Œå›æ»šã€‚
    é‡‡ç”¨æ ‡å‡† unified diff ç¼–è¾‘èŒƒå¼ã€‚
    """

    def __init__(self):
        super().__init__(
            name="apply_patch",
            description="åº”ç”¨ unified diff åˆ°æ–‡ä»¶ã€‚è¾“å…¥ä¸ºæ ‡å‡† diff æ–‡æœ¬ï¼ˆ---/+++ æ–‡ä»¶è·¯å¾„ï¼Œ@@ hunkï¼Œ- åˆ é™¤è¡Œï¼Œ+ æ·»åŠ è¡Œï¼‰ã€‚è·¯å¾„ä¸ºç›¸å¯¹é¡¹ç›®æ ¹ã€‚"
        )

    async def execute(
        self,
        diff: str,
        base_path: Optional[str] = None
    ) -> ToolResult:
        """
        åº”ç”¨ diffã€‚
        
        Args:
            diff: unified diff å­—ç¬¦ä¸²ï¼ˆå¯å«å¤šä¸ªæ–‡ä»¶ï¼‰
            base_path: ç›¸å¯¹è·¯å¾„çš„åŸºå‡†ç›®å½•ï¼Œé»˜è®¤ä½¿ç”¨å½“å‰ä»“åº“æ ¹
        """
        try:
            base = self.context.repo_path
            if base_path:
                base = self.resolve_path(base_path)
            parsed = _parse_unified_diff(diff)
            applied = []
            errors = []
            for file_info in parsed:
                rel_path = file_info["path"]
                full_path = base / rel_path
                if not full_path.exists() and not any(h[4] for h in file_info["hunks"] if any(l.startswith("+") for l in h[4])):
                    errors.append(f"æ–‡ä»¶ä¸å­˜åœ¨ä¸”æ— æ–°å¢å†…å®¹: {rel_path}")
                    continue
                try:
                    if full_path.exists():
                        content = full_path.read_text(encoding="utf-8", errors="ignore")
                        old_lines = content.splitlines(keepends=True)
                        if not content.endswith("\n") and old_lines:
                            old_lines[-1] = old_lines[-1].rstrip("\n") + "\n"
                    else:
                        full_path.parent.mkdir(parents=True, exist_ok=True)
                        old_lines = []
                    for (old_start, old_count, new_start, new_count, hunk_lines) in file_info["hunks"]:
                        old_lines = _apply_hunk(old_lines, old_start, old_count, new_start, new_count, hunk_lines)
                    full_path.write_text("".join(old_lines), encoding="utf-8")
                    applied.append(rel_path)
                except Exception as e:
                    errors.append(f"{rel_path}: {e}")
            if errors and not applied:
                return ToolResult(success=False, content=None, error="; ".join(errors))
            return ToolResult(
                success=True,
                content=f"å·²åº”ç”¨ diff åˆ°: {', '.join(applied)}" + ("; é”™è¯¯: " + "; ".join(errors) if errors else ""),
                metadata={"applied": applied, "errors": errors if errors else None}
            )
        except Exception as e:
            return ToolResult(success=False, content=None, error=str(e))

    def get_function_schema(self) -> Dict[str, Any]:
        return {
            "name": self.name,
            "description": self.description,
            "parameters": {
                "type": "object",
                "properties": {
                    "diff": {
                        "type": "string",
                        "description": "Unified diff å…¨æ–‡ï¼ˆåŒ…å« ---/+++ è·¯å¾„å’Œ @@ hunkï¼‰"
                    },
                    "base_path": {
                        "type": "string",
                        "description": "ç›¸å¯¹è·¯å¾„åŸºå‡†ï¼Œé»˜è®¤å½“å‰ä»“åº“æ ¹ã€‚ä½¿ç”¨ '.' è¡¨ç¤ºä»“åº“æ ¹"
                    }
                },
                "required": ["diff"]
            }
        }
