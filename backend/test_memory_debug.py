"""
Memoryç³»ç»Ÿå®æˆ˜è°ƒè¯•è„šæœ¬

ç”¨äºåœ¨å®é™…ä½¿ç”¨ä¸­è¿½è¸ªMemoryç³»ç»Ÿçš„è¡Œä¸º
"""

import asyncio
import logging
from daoyoucode.agents.memory import get_memory_manager

# é…ç½®æ—¥å¿— - å¯ä»¥è°ƒæ•´çº§åˆ«
logging.basicConfig(
    level=logging.INFO,  # æ”¹ä¸º DEBUG å¯ä»¥çœ‹åˆ°æ›´è¯¦ç»†çš„ä¿¡æ¯
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

logger = logging.getLogger(__name__)


async def simulate_conversation():
    """æ¨¡æ‹Ÿä¸€ä¸ªå®Œæ•´çš„å¯¹è¯æµç¨‹"""
    print("\n" + "="*60)
    print("Memoryç³»ç»Ÿå®æˆ˜è°ƒè¯•")
    print("="*60)
    
    memory = get_memory_manager()
    session_id = "debug-session"
    user_id = "debug-user"
    
    # æ¨¡æ‹Ÿå¯¹è¯åœºæ™¯
    conversations = [
        ("è¿™ä¸ªé¡¹ç›®æ˜¯åšä»€ä¹ˆçš„ï¼Ÿ", "è¿™æ˜¯ä¸€ä¸ªAIä»£ç åŠ©æ‰‹é¡¹ç›®ï¼Œåä¸ºDaoyouCode..."),
        ("æœ‰å“ªäº›æ ¸å¿ƒåŠŸèƒ½ï¼Ÿ", "æ ¸å¿ƒåŠŸèƒ½åŒ…æ‹¬ï¼šä»£ç ç¼–è¾‘ã€é‡æ„ã€æµ‹è¯•ç”Ÿæˆã€æ–‡æ¡£ç”Ÿæˆ..."),
        ("Agentç³»ç»Ÿæ˜¯æ€ä¹ˆå·¥ä½œçš„ï¼Ÿ", "Agentç³»ç»Ÿä½¿ç”¨å¯æ’æ‹”æ¶æ„ï¼ŒåŒ…å«ç¼–æ’å™¨ã€å·¥å…·ã€è®°å¿†ç­‰æ¨¡å—..."),
        ("èƒ½è¯¦ç»†è¯´è¯´ç¼–æ’å™¨å—ï¼Ÿ", "ç¼–æ’å™¨æœ‰ä¸‰ç§ç±»å‹ï¼šSimpleã€ReActã€Parallel..."),
        ("å·¥å…·ç³»ç»Ÿæœ‰å“ªäº›å·¥å…·ï¼Ÿ", "å·¥å…·ç³»ç»Ÿæœ‰25ä¸ªå·¥å…·ï¼ŒåŒ…æ‹¬æ–‡ä»¶æ“ä½œã€ä»£ç åˆ†æã€æµ‹è¯•æ‰§è¡Œç­‰..."),
        ("Memoryç³»ç»Ÿæœ‰ä»€ä¹ˆç‰¹ç‚¹ï¼Ÿ", "Memoryç³»ç»Ÿæ”¯æŒæ™ºèƒ½åŠ è½½ã€æ‘˜è¦ç”Ÿæˆã€ç”¨æˆ·ç”»åƒç­‰åŠŸèƒ½..."),
        ("èƒ½å†è¯¦ç»†è¯´è¯´æ™ºèƒ½åŠ è½½å—ï¼Ÿ", "æ™ºèƒ½åŠ è½½æœ‰5ç§ç­–ç•¥ï¼Œå¯ä»¥èŠ‚çœ50-70%çš„tokenæˆæœ¬..."),
    ]
    
    for idx, (user_msg, ai_msg) in enumerate(conversations, 1):
        print(f"\n{'='*60}")
        print(f"ç¬¬{idx}è½®å¯¹è¯")
        print(f"{'='*60}")
        print(f"ğŸ‘¤ ç”¨æˆ·: {user_msg}")
        
        # åˆ¤æ–­è¿½é—®
        if idx > 1:
            is_followup, confidence, reason = await memory.is_followup(
                session_id, user_msg
            )
            print(f"\nğŸ” è¿½é—®åˆ¤æ–­:")
            print(f"   ç»“æœ: {'æ˜¯è¿½é—®' if is_followup else 'æ–°è¯é¢˜'}")
            print(f"   ç½®ä¿¡åº¦: {confidence:.2f}")
            print(f"   åŸå› : {reason}")
        else:
            is_followup, confidence = False, 0.0
            print(f"\nğŸ” è¿½é—®åˆ¤æ–­: é¦–è½®å¯¹è¯ï¼Œæ— éœ€åˆ¤æ–­")
        
        # æ™ºèƒ½åŠ è½½
        print(f"\nğŸ“š æ™ºèƒ½åŠ è½½:")
        context = await memory.load_context_smart(
            session_id=session_id,
            user_id=user_id,
            user_input=user_msg,
            is_followup=is_followup,
            confidence=confidence
        )
        
        print(f"   ç­–ç•¥: {context['strategy']}")
        print(f"   å†å²è½®æ•°: {len(context['history'])}")
        print(f"   æˆæœ¬: {context['cost']}")
        print(f"   æ™ºèƒ½ç­›é€‰: {'æ˜¯' if context.get('filtered') else 'å¦'}")
        
        if context['history']:
            print(f"   åŠ è½½çš„å¯¹è¯:")
            for h_idx, h in enumerate(context['history'], 1):
                print(f"     {h_idx}. {h['user'][:50]}...")
        
        if context.get('summary'):
            print(f"   æ‘˜è¦: {context['summary'][:100]}...")
        
        # æ¨¡æ‹ŸAIå“åº”
        print(f"\nğŸ¤– AI: {ai_msg[:80]}...")
        
        # æ·»åŠ åˆ°è®°å¿†
        memory.add_conversation(session_id, user_msg, ai_msg)
        
        # æ£€æŸ¥æ‘˜è¦è§¦å‘
        history = memory.get_conversation_history(session_id)
        if memory.long_term_memory.should_generate_summary(session_id, len(history)):
            print(f"\nğŸ”„ è§¦å‘æ‘˜è¦ç”Ÿæˆæ¡ä»¶ï¼ˆå½“å‰{len(history)}è½®ï¼‰")
            print(f"   ğŸ’¡ åœ¨å®é™…ä½¿ç”¨ä¸­ï¼ŒAgentä¼šè‡ªåŠ¨è°ƒç”¨LLMç”Ÿæˆæ‘˜è¦")
        
        # æš‚åœä¸€ä¸‹ï¼Œæ–¹ä¾¿è§‚å¯Ÿ
        await asyncio.sleep(0.1)
    
    # æœ€ç»ˆç»Ÿè®¡
    print(f"\n{'='*60}")
    print("æœ€ç»ˆç»Ÿè®¡")
    print(f"{'='*60}")
    
    # æ™ºèƒ½åŠ è½½ç»Ÿè®¡
    loader_stats = memory.smart_loader.get_stats()
    print(f"\nğŸ“Š æ™ºèƒ½åŠ è½½ç»Ÿè®¡:")
    print(f"   æ€»åŠ è½½æ¬¡æ•°: {loader_stats['total_loads']}")
    print(f"   å¹³å‡æˆæœ¬: {loader_stats['average_cost']:.2f}")
    print(f"   ç­–ç•¥åˆ†å¸ƒ:")
    for strategy in ['new_conversation', 'simple_followup', 'medium_followup', 
                     'complex_followup', 'cross_session']:
        count = loader_stats.get(strategy, 0)
        if count > 0:
            percentage = count / loader_stats['total_loads'] * 100
            print(f"     - {strategy}: {count} ({percentage:.1f}%)")
    
    # å­˜å‚¨ç»Ÿè®¡
    storage_stats = memory.storage.get_stats()
    print(f"\nğŸ“¦ å­˜å‚¨ç»Ÿè®¡:")
    print(f"   æ€»ä¼šè¯æ•°: {storage_stats['total_sessions']}")
    print(f"   æ€»å¯¹è¯æ•°: {storage_stats['total_conversations']}")
    print(f"   æ‘˜è¦æ•°: {storage_stats['summaries']}")
    print(f"   ç”¨æˆ·ç”»åƒæ•°: {storage_stats['user_profiles']}")
    
    print(f"\nâœ… è°ƒè¯•å®Œæˆï¼")


async def test_specific_scenario():
    """æµ‹è¯•ç‰¹å®šåœºæ™¯"""
    print("\n" + "="*60)
    print("æµ‹è¯•ç‰¹å®šåœºæ™¯ï¼šå…³é”®è¯ç­›é€‰")
    print("="*60)
    
    memory = get_memory_manager()
    session_id = "test-filter"
    user_id = "test-user"
    
    # æ·»åŠ å¤šæ ·åŒ–çš„å†å²
    conversations = [
        ("è¿™ä¸ªé¡¹ç›®çš„ç»“æ„æ˜¯ä»€ä¹ˆï¼Ÿ", "é¡¹ç›®åŒ…å«backendã€frontendã€aiç­‰æ¨¡å—..."),
        ("Agentç³»ç»Ÿåœ¨å“ªé‡Œï¼Ÿ", "Agentç³»ç»Ÿåœ¨backend/daoyoucode/agents/..."),
        ("ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ", "æŠ±æ­‰ï¼Œæˆ‘æ˜¯ä»£ç åŠ©æ‰‹ï¼Œä¸èƒ½æŸ¥è¯¢å¤©æ°”..."),
        ("Memoryç³»ç»Ÿæœ‰ä»€ä¹ˆåŠŸèƒ½ï¼Ÿ", "Memoryç³»ç»Ÿæ”¯æŒæ™ºèƒ½åŠ è½½ã€æ‘˜è¦ç”Ÿæˆ..."),
        ("å·¥å…·æ³¨å†Œè¡¨æ€ä¹ˆå·¥ä½œçš„ï¼Ÿ", "å·¥å…·æ³¨å†Œè¡¨ä½¿ç”¨å•ä¾‹æ¨¡å¼..."),
    ]
    
    for user_msg, ai_msg in conversations:
        memory.add_conversation(session_id, user_msg, ai_msg)
    
    print(f"âœ… æ·»åŠ äº† {len(conversations)} è½®å¯¹è¯")
    
    # æµ‹è¯•ä¸åŒçš„æŸ¥è¯¢
    test_queries = [
        "Memoryç³»ç»Ÿçš„æ™ºèƒ½åŠ è½½æ˜¯æ€ä¹ˆå·¥ä½œçš„ï¼Ÿ",
        "Agentç³»ç»Ÿæœ‰å“ªäº›ç»„ä»¶ï¼Ÿ",
        "ä»Šå¤©åƒä»€ä¹ˆï¼Ÿ",
    ]
    
    for query in test_queries:
        print(f"\n{'='*60}")
        print(f"æŸ¥è¯¢: {query}")
        print(f"{'='*60}")
        
        context = await memory.load_context_smart(
            session_id=session_id,
            user_id=user_id,
            user_input=query,
            is_followup=False
        )
        
        print(f"ç­–ç•¥: {context['strategy']}")
        print(f"åŠ è½½è½®æ•°: {len(context['history'])}")
        print(f"æ™ºèƒ½ç­›é€‰: {'æ˜¯' if context.get('filtered') else 'å¦'}")
        
        if context['history']:
            print(f"åŠ è½½çš„å¯¹è¯:")
            for idx, h in enumerate(context['history'], 1):
                print(f"  {idx}. {h['user']}")


async def test_token_savings():
    """æµ‹è¯•TokenèŠ‚çœæ•ˆæœ"""
    print("\n" + "="*60)
    print("æµ‹è¯•TokenèŠ‚çœæ•ˆæœ")
    print("="*60)
    
    memory = get_memory_manager()
    session_id = "test-tokens"
    user_id = "test-user"
    
    # æ·»åŠ 10è½®å¯¹è¯
    for i in range(10):
        memory.add_conversation(
            session_id,
            f"é—®é¢˜{i+1}: è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•é—®é¢˜ï¼Œç”¨äºè®¡ç®—tokenä½¿ç”¨æƒ…å†µ...",
            f"å›ç­”{i+1}: è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•å›ç­”ï¼ŒåŒ…å«äº†è¯¦ç»†çš„è§£é‡Šå’Œä»£ç ç¤ºä¾‹..."
        )
    
    # è·å–å®Œæ•´å†å²
    full_history = memory.get_conversation_history(session_id)
    
    # è®¡ç®—å®Œæ•´å†å²çš„tokenæ•°ï¼ˆç²—ç•¥ä¼°ç®—ï¼š4å­—ç¬¦=1tokenï¼‰
    full_tokens = sum(
        len(h['user']) + len(h['ai'])
        for h in full_history
    ) // 4
    
    print(f"\nå®Œæ•´å†å²:")
    print(f"  è½®æ•°: {len(full_history)}")
    print(f"  ä¼°ç®—tokens: {full_tokens}")
    
    # ä½¿ç”¨æ™ºèƒ½åŠ è½½
    context = await memory.load_context_smart(
        session_id=session_id,
        user_id=user_id,
        user_input="èƒ½è¯¦ç»†è¯´è¯´å—ï¼Ÿ",
        is_followup=True,
        confidence=0.9
    )
    
    # è®¡ç®—æ™ºèƒ½åŠ è½½çš„tokenæ•°
    smart_tokens = sum(
        len(h['user']) + len(h['ai'])
        for h in context['history']
    ) // 4
    
    print(f"\næ™ºèƒ½åŠ è½½:")
    print(f"  ç­–ç•¥: {context['strategy']}")
    print(f"  è½®æ•°: {len(context['history'])}")
    print(f"  ä¼°ç®—tokens: {smart_tokens}")
    
    # è®¡ç®—èŠ‚çœ
    saved_tokens = full_tokens - smart_tokens
    saved_percentage = (saved_tokens / full_tokens * 100) if full_tokens > 0 else 0
    
    print(f"\nğŸ’° èŠ‚çœæ•ˆæœ:")
    print(f"  èŠ‚çœtokens: {saved_tokens}")
    print(f"  èŠ‚çœæ¯”ä¾‹: {saved_percentage:.1f}%")


async def main():
    """ä¸»å‡½æ•°"""
    print("\n" + "="*60)
    print("Memoryç³»ç»Ÿå®æˆ˜è°ƒè¯•å·¥å…·")
    print("="*60)
    print("\né€‰æ‹©æµ‹è¯•åœºæ™¯:")
    print("1. å®Œæ•´å¯¹è¯æµç¨‹ï¼ˆæ¨èï¼‰")
    print("2. å…³é”®è¯ç­›é€‰æµ‹è¯•")
    print("3. TokenèŠ‚çœæ•ˆæœæµ‹è¯•")
    print("4. è¿è¡Œæ‰€æœ‰æµ‹è¯•")
    
    # é»˜è®¤è¿è¡Œå®Œæ•´æµç¨‹
    choice = "1"
    
    # å¦‚æœéœ€è¦äº¤äº’å¼é€‰æ‹©ï¼Œå–æ¶ˆä¸‹é¢çš„æ³¨é‡Š
    # choice = input("\nè¯·é€‰æ‹© (1-4): ").strip()
    
    if choice == "1":
        await simulate_conversation()
    elif choice == "2":
        await test_specific_scenario()
    elif choice == "3":
        await test_token_savings()
    elif choice == "4":
        await simulate_conversation()
        await test_specific_scenario()
        await test_token_savings()
    else:
        print("é»˜è®¤è¿è¡Œå®Œæ•´å¯¹è¯æµç¨‹...")
        await simulate_conversation()


if __name__ == "__main__":
    asyncio.run(main())
