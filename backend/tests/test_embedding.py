"""
æµ‹è¯•EmbeddingåŠŸèƒ½

éªŒè¯ï¼š
1. sentence-transformersæ˜¯å¦æ­£ç¡®å®‰è£…
2. æ¨¡å‹æ˜¯å¦èƒ½æ­£ç¡®åŠ è½½
3. æ–‡æœ¬ç¼–ç æ˜¯å¦æ­£å¸¸
4. ç›¸ä¼¼åº¦è®¡ç®—æ˜¯å¦æ­£ç¡®
5. å‘é‡æ£€ç´¢æ˜¯å¦å¯ç”¨
"""

import asyncio
import logging

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

logger = logging.getLogger(__name__)


async def test_import():
    """æµ‹è¯•1ï¼šå¯¼å…¥ä¾èµ–"""
    print("=" * 60)
    print("æµ‹è¯•1ï¼šå¯¼å…¥ä¾èµ–")
    print("=" * 60)
    
    try:
        import sentence_transformers
        print(f"âœ… sentence-transformers ç‰ˆæœ¬: {sentence_transformers.__version__}")
    except ImportError as e:
        print(f"âŒ sentence-transformers æœªå®‰è£…: {e}")
        print("ğŸ’¡ å®‰è£…å‘½ä»¤: pip install sentence-transformers")
        return False
    
    try:
        import numpy as np
        print(f"âœ… numpy ç‰ˆæœ¬: {np.__version__}")
    except ImportError as e:
        print(f"âŒ numpy æœªå®‰è£…: {e}")
        return False
    
    try:
        import torch
        print(f"âœ… torch ç‰ˆæœ¬: {torch.__version__}")
    except ImportError as e:
        print(f"âŒ torch æœªå®‰è£…: {e}")
        return False
    
    return True


async def test_vector_retriever():
    """æµ‹è¯•2ï¼šVectorRetrieveråˆå§‹åŒ–"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•2ï¼šVectorRetrieveråˆå§‹åŒ–")
    print("=" * 60)
    
    try:
        from daoyoucode.agents.memory.vector_retriever import VectorRetriever
        
        print("ğŸ”„ åˆ›å»ºVectorRetrieverå®ä¾‹...")
        retriever = VectorRetriever()
        
        if retriever.enabled:
            print(f"âœ… å‘é‡æ£€ç´¢å·²å¯ç”¨")
            print(f"   æ¨¡å‹: {retriever.model_name}")
            
            # è·å–ç»Ÿè®¡ä¿¡æ¯
            stats = retriever.get_stats()
            print(f"   ç»´åº¦: {stats.get('embedding_dim', 'unknown')}")
            
            return True
        else:
            print("âŒ å‘é‡æ£€ç´¢æœªå¯ç”¨")
            return False
    
    except Exception as e:
        print(f"âŒ åˆå§‹åŒ–å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


async def test_encode():
    """æµ‹è¯•3ï¼šæ–‡æœ¬ç¼–ç """
    print("\n" + "=" * 60)
    print("æµ‹è¯•3ï¼šæ–‡æœ¬ç¼–ç ")
    print("=" * 60)
    
    try:
        from daoyoucode.agents.memory.vector_retriever import get_vector_retriever
        
        retriever = get_vector_retriever()
        
        if not retriever.enabled:
            print("âš ï¸ å‘é‡æ£€ç´¢æœªå¯ç”¨ï¼Œè·³è¿‡æµ‹è¯•")
            return False
        
        # æµ‹è¯•ç¼–ç 
        test_texts = [
            "å¦‚ä½•ä¿®å¤Agentæ‰§è¡Œæ—¶çš„è¶…æ—¶é”™è¯¯ï¼Ÿ",
            "Agent timeout error fix",
            "Pythonå‡½æ•°å®šä¹‰",
            "class BaseAgent"
        ]
        
        print("\nç¼–ç æµ‹è¯•:")
        for text in test_texts:
            embedding = retriever.encode(text)
            if embedding is not None:
                print(f"âœ… '{text}' â†’ å‘é‡ç»´åº¦: {embedding.shape}")
            else:
                print(f"âŒ '{text}' â†’ ç¼–ç å¤±è´¥")
                return False
        
        return True
    
    except Exception as e:
        print(f"âŒ ç¼–ç æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


async def test_similarity():
    """æµ‹è¯•4ï¼šç›¸ä¼¼åº¦è®¡ç®—"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•4ï¼šç›¸ä¼¼åº¦è®¡ç®—")
    print("=" * 60)
    
    try:
        from daoyoucode.agents.memory.vector_retriever import get_vector_retriever
        
        retriever = get_vector_retriever()
        
        if not retriever.enabled:
            print("âš ï¸ å‘é‡æ£€ç´¢æœªå¯ç”¨ï¼Œè·³è¿‡æµ‹è¯•")
            return False
        
        # æµ‹è¯•ç›¸ä¼¼åº¦
        test_pairs = [
            ("å¦‚ä½•ä¿®å¤è¶…æ—¶é”™è¯¯", "timeout error fix"),
            ("Pythonå‡½æ•°", "Python function"),
            ("çŒ«å’ª", "å°çŒ«"),
            ("è‹¹æœ", "é¦™è•‰"),
            ("ç¼–ç¨‹", "åšé¥­")
        ]
        
        print("\nç›¸ä¼¼åº¦æµ‹è¯•:")
        for text1, text2 in test_pairs:
            emb1 = retriever.encode(text1)
            emb2 = retriever.encode(text2)
            
            if emb1 is not None and emb2 is not None:
                similarity = retriever.cosine_similarity(emb1, emb2)
                print(f"  '{text1}' vs '{text2}': {similarity:.4f}")
            else:
                print(f"âŒ ç¼–ç å¤±è´¥")
                return False
        
        return True
    
    except Exception as e:
        print(f"âŒ ç›¸ä¼¼åº¦æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


async def test_codebase_index():
    """æµ‹è¯•5ï¼šCodebaseIndexé›†æˆ"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•5ï¼šCodebaseIndexé›†æˆ")
    print("=" * 60)
    
    try:
        from pathlib import Path
        from daoyoucode.agents.memory.codebase_index import CodebaseIndex
        
        print("ğŸ”„ åˆ›å»ºCodebaseIndex...")
        index = CodebaseIndex(Path("."))
        
        print("ğŸ”„ æ„å»ºç´¢å¼•ï¼ˆå¼ºåˆ¶é‡å»ºï¼‰...")
        chunk_count = index.build_index(force=True)
        
        print(f"âœ… ç´¢å¼•æ„å»ºå®Œæˆ: {chunk_count} chunks")
        
        # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨äº†å‘é‡
        if index.embeddings is not None:
            print(f"âœ… å‘é‡å·²ç”Ÿæˆ: {index.embeddings.shape}")
        else:
            print("âš ï¸ æœªç”Ÿæˆå‘é‡ï¼ˆå¯èƒ½ä½¿ç”¨å…³é”®è¯å›é€€ï¼‰")
        
        # æµ‹è¯•æ£€ç´¢
        print("\nğŸ” æµ‹è¯•æ£€ç´¢:")
        query = "agent execute timeout"
        results = index.search(query, top_k=3)
        
        print(f"   æŸ¥è¯¢: '{query}'")
        print(f"   ç»“æœæ•°: {len(results)}")
        
        for i, result in enumerate(results[:3], 1):
            print(f"\n   {i}. {result.get('path')}")
            print(f"      åç§°: {result.get('name')}")
            print(f"      ç±»å‹: {result.get('type')}")
            print(f"      åˆ†æ•°: {result.get('score', 0.0):.4f}")
        
        return True
    
    except Exception as e:
        print(f"âŒ CodebaseIndexæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


async def main():
    """ä¸»å‡½æ•°"""
    print("æµ‹è¯•EmbeddingåŠŸèƒ½\n")
    
    results = []
    
    # æµ‹è¯•1ï¼šå¯¼å…¥ä¾èµ–
    result = await test_import()
    results.append(("import", result))
    
    if not result:
        print("\nâŒ ä¾èµ–æœªå®‰è£…ï¼Œè¯·å…ˆå®‰è£…:")
        print("   pip install sentence-transformers numpy torch")
        return False
    
    # æµ‹è¯•2ï¼šVectorRetrieveråˆå§‹åŒ–
    result = await test_vector_retriever()
    results.append(("vector_retriever", result))
    
    if not result:
        print("\nâŒ VectorRetrieveråˆå§‹åŒ–å¤±è´¥")
        return False
    
    # æµ‹è¯•3ï¼šæ–‡æœ¬ç¼–ç 
    result = await test_encode()
    results.append(("encode", result))
    
    # æµ‹è¯•4ï¼šç›¸ä¼¼åº¦è®¡ç®—
    result = await test_similarity()
    results.append(("similarity", result))
    
    # æµ‹è¯•5ï¼šCodebaseIndexé›†æˆ
    result = await test_codebase_index()
    results.append(("codebase_index", result))
    
    # æ€»ç»“
    print("\n" + "=" * 60)
    print("æµ‹è¯•æ€»ç»“")
    print("=" * 60)
    
    for test_name, result in results:
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"{status} - {test_name}")
    
    all_passed = all(result for _, result in results)
    
    if all_passed:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼EmbeddingåŠŸèƒ½å·²æ­£å¸¸å¯ç”¨")
        print("\nä¸‹ä¸€æ­¥:")
        print("  1. é‡æ–°æ„å»ºä»£ç ç´¢å¼•: index.build_index(force=True)")
        print("  2. äº«å—æ›´ç²¾å‡†çš„è¯­ä¹‰æ£€ç´¢")
    else:
        print("\nâš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥")
        print("\næ•…éšœæ’é™¤:")
        print("  1. ç¡®ä¿å·²å®‰è£…ä¾èµ–: pip install -r requirements.txt")
        print("  2. æ£€æŸ¥ç½‘ç»œè¿æ¥ï¼ˆé¦–æ¬¡ä½¿ç”¨ä¼šä¸‹è½½æ¨¡å‹ï¼‰")
        print("  3. æŸ¥çœ‹ä¸Šé¢çš„é”™è¯¯ä¿¡æ¯")
    
    return all_passed


if __name__ == "__main__":
    asyncio.run(main())
