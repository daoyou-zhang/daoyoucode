# 向量模型切换验证

## 当前配置验证 ✅

### 1. 配置文件分析

**配置文件**: `config/embedding_config.yaml`

```yaml
mode: "api"  # ✅ 使用API模式

api:
  provider: "zhipu"  # ✅ 当前使用智谱AI
  api_key: "f7def1d8285a4b1da14f903a91a330a9.qwwPt8zwziMJIAmY"
```

### 2. 工作流程确认

**工厂函数**: `vector_retriever_factory.py`

```python
mode = config.get("mode", "api")

if mode == "api":
    # ✅ 使用API模式 - 不依赖huggingface
    from .vector_retriever_api import VectorRetrieverAPI
    
    retriever = VectorRetrieverAPI(
        provider=provider,
        api_key=api_key
    )
else:
    # 本地模式 - 使用sentence_transformers（备选方案）
    from .vector_retriever import VectorRetriever
    
    retriever = VectorRetriever(model_name=model_name)
```

**结论**: 
- ✅ 当前配置 `mode="api"` 时，系统使用 `VectorRetrieverAPI`
- ✅ `VectorRetrieverAPI` 使用 `httpx` 调用API，不依赖 `huggingface`
- ✅ `vector_retriever.py`（本地模型版本）仅在 `mode="local"` 时使用

### 3. API模式实现

**API客户端**: `vector_retriever_api.py`

```python
# ✅ 使用httpx调用API，不依赖huggingface
self.client = httpx.Client(
    base_url=self.base_url,
    headers={
        "Authorization": f"Bearer {self.api_key}",
        "Content-Type": "application/json"
    },
    timeout=30.0
)

# ✅ 调用API获取向量
response = self.client.post(
    "/embeddings",
    json={
        "model": self.model,
        "input": text
    }
)
```

**结论**: 
- ✅ 完全使用HTTP API，不依赖本地模型
- ✅ 不需要下载模型文件
- ✅ 不需要 `sentence_transformers` 或 `huggingface_hub`

---

## 切换到千问向量模型

### 方法1: 修改配置文件（推荐）

**步骤**: 只需修改 `config/embedding_config.yaml`

```yaml
mode: "api"

api:
  provider: "qwen"  # 改为千问
  api_key: "YOUR_DASHSCOPE_API_KEY"  # 千问的API Key
```

**千问配置详情**:
```python
"qwen": {
    "base_url": "https://dashscope.aliyuncs.com/compatible-mode/v1",
    "model": "text-embedding-v3",
    "dimensions": 1024,
    "env_key": "DASHSCOPE_API_KEY"
}
```

### 方法2: 使用环境变量

**步骤1**: 设置环境变量
```bash
# Windows CMD
set DASHSCOPE_API_KEY=your_api_key_here

# Windows PowerShell
$env:DASHSCOPE_API_KEY="your_api_key_here"
```

**步骤2**: 修改配置文件（不写api_key）
```yaml
mode: "api"

api:
  provider: "qwen"
  # api_key留空，从环境变量读取
```

### 方法3: 切换到OpenAI

```yaml
mode: "api"

api:
  provider: "openai"
  api_key: "sk-..."  # OpenAI API Key
```

**OpenAI配置详情**:
```python
"openai": {
    "base_url": "https://api.openai.com/v1",
    "model": "text-embedding-3-small",
    "dimensions": 1536,
    "env_key": "OPENAI_API_KEY"
}
```

---

## 切换后无需重新安装依赖 ✅

### 为什么？

1. **API模式不依赖本地库**
   - 智谱AI、千问、OpenAI都使用HTTP API
   - 只需要 `httpx` 库（已安装）

2. **依赖已经满足**
   ```
   httpx>=0.24.0  # ✅ 已安装
   numpy>=1.21.0  # ✅ 已安装
   pyyaml>=6.0    # ✅ 已安装
   ```

3. **本地模型库是可选的**
   - `sentence_transformers` 仅在 `mode="local"` 时需要
   - API模式不会加载这些库

### 验证方法

**测试切换到千问**:

```python
# test_qwen_embedding.py
from daoyoucode.agents.memory.vector_retriever_api import VectorRetrieverAPI

# 创建千问检索器
retriever = VectorRetrieverAPI(
    provider="qwen",
    api_key="YOUR_DASHSCOPE_API_KEY"
)

# 测试编码
text = "这是一个测试文本"
embedding = retriever.encode(text)

print(f"✅ 千问向量维度: {len(embedding)}")  # 应该是1024
print(f"✅ 向量前5维: {embedding[:5]}")
```

---

## 三种提供商对比

| 提供商 | 模型 | 维度 | 优势 | API Key环境变量 |
|--------|------|------|------|----------------|
| 智谱AI | embedding-3 | 2048 | 维度最高，中文效果好 | ZHIPU_API_KEY |
| 千问 | text-embedding-v3 | 1024 | 阿里云生态，稳定 | DASHSCOPE_API_KEY |
| OpenAI | text-embedding-3-small | 1536 | 国际标准，英文最优 | OPENAI_API_KEY |

---

## 常见问题

### Q1: 切换模型后需要重建索引吗？

**A**: 需要！不同模型的向量维度和语义空间不同。

```bash
# 删除旧索引
rm -rf .daoyoucode/codebase_index

# 重新构建（会自动使用新模型）
python -m daoyoucode.agents.memory.codebase_index
```

### Q2: 如何确认当前使用的是哪个模型？

**A**: 查看日志输出

```
✅ 向量检索已启用（API模式）
   提供商: zhipu
   模型: embedding-3
   维度: 2048
```

### Q3: 可以同时使用多个提供商吗？

**A**: 不支持。但可以通过修改配置文件快速切换。

### Q4: API调用失败会怎样？

**A**: 自动回退到关键词匹配（不影响系统运行）

```
⚠️ API请求失败: 401
   回退到关键词匹配模式
```

---

## 总结

✅ **当前状态**: 完全使用API模式（智谱AI），不依赖huggingface

✅ **切换方法**: 只需修改配置文件中的 `provider` 和 `api_key`

✅ **无需重装**: 所有API提供商共享相同的依赖（httpx）

✅ **灵活切换**: 支持智谱AI、千问、OpenAI三种提供商

✅ **自动回退**: API失败时自动使用关键词匹配

---

**下一步**: 如需切换到千问，请提供千问的API Key，我将帮你更新配置并测试。
