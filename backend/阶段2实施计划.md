# 阶段2实施计划：增强Chunk结构

## 目标

在阶段1的基础上，增强chunk结构，添加：
1. 引用关系（calls, called_by）
2. 导入关系（imports, imported_by）
3. 文件关联（related_files）
4. 父级信息（parent_class）
5. 作用域信息（scope）

## 当前Chunk结构（阶段1）

```python
{
    "path": "backend/agents/core/agent.py",
    "start": 100,
    "end": 150,
    "text": "def execute(self, ...):\n    ...",
    # 🆕 阶段1已添加
    "type": "method",
    "name": "execute",
    "pagerank_score": 0.85
}
```

## 目标Chunk结构（阶段2）

```python
{
    # 基础信息（阶段1）
    "path": "backend/agents/core/agent.py",
    "start": 100,
    "end": 150,
    "text": "def execute(self, ...):\n    ...",
    "type": "method",
    "name": "execute",
    "pagerank_score": 0.85,
    
    # 🆕 阶段2新增
    "parent_class": "BaseAgent",  # 所属类
    "scope": "class",  # "global" | "class" | "function"
    
    # 🆕 引用关系
    "calls": [  # 这个函数调用了谁
        "_load_prompt",
        "_call_llm_with_tools",
        "get_tool_registry"
    ],
    "called_by": [  # 这个函数被谁调用（文件级别）
        "backend/orchestrators/multi_agent.py",
        "backend/executor.py"
    ],
    
    # 🆕 导入关系
    "imports": [  # 这个文件导入了什么
        "from ..llm import get_client_manager",
        "from ..tools import get_tool_registry"
    ],
    
    # 🆕 文件关联
    "related_files": [  # 相关文件（基于引用图）
        "backend/agents/llm/client_manager.py",
        "backend/agents/tools/registry.py",
        "backend/orchestrators/multi_agent.py"
    ]
}
```

## 实施步骤

### 步骤1: 增强RepoMap的Definition结构

**文件**: `backend/daoyoucode/agents/tools/repomap_tools.py`

**任务**: 在`_parse_file()`中添加parent和scope信息

**修改点**:
```python
def _parse_file(self, file_path: Path, lang: str) -> List[Dict]:
    """解析文件，提取定义和引用（增强版）"""
    
    # ... 原有逻辑 ...
    
    parent_stack = []  # 🆕 跟踪父级
    
    for pattern_index, captures_dict in matches:
        for tag, nodes in captures_dict.items():
            for node in nodes:
                if tag.startswith("name.definition."):
                    # ... 原有逻辑 ...
                    
                    # 🆕 确定父级
                    parent = parent_stack[-1] if parent_stack else None
                    
                    # 🆕 确定作用域
                    if type_name == "class":
                        scope = "global"
                        parent_stack.append(name)
                    elif type_name in ("function", "method"):
                        scope = "class" if parent else "global"
                    else:
                        scope = "global"
                    
                    definitions.append({
                        # ... 原有字段 ...
                        "parent": parent,  # 🆕
                        "scope": scope,    # 🆕
                    })
```

### 步骤2: 提取函数调用关系

**文件**: `backend/daoyoucode/agents/memory/codebase_index.py`

**任务**: 添加`_extract_calls()`方法，从代码文本中提取函数调用

**新增方法**:
```python
def _extract_calls(self, code_text: str, language: str = "python") -> List[str]:
    """
    从代码中提取函数调用
    
    策略：
    1. Python: 正则匹配 identifier(
    2. 过滤常见关键字（if, for, while等）
    3. 去重
    """
    import re
    
    if language == "python":
        # 匹配函数调用：identifier(
        pattern = r'(\w+)\s*\('
        calls = re.findall(pattern, code_text)
        
        # 过滤Python关键字
        keywords = {
            'if', 'for', 'while', 'def', 'class', 'return',
            'import', 'from', 'try', 'except', 'with', 'as',
            'print', 'len', 'str', 'int', 'float', 'list', 'dict'
        }
        calls = [c for c in calls if c not in keywords]
        
        # 去重并排序
        return sorted(set(calls))
    
    return []
```

### 步骤3: 提取导入关系

**文件**: `backend/daoyoucode/agents/memory/codebase_index.py`

**任务**: 添加`_extract_imports()`方法，提取文件的导入语句

**新增方法**:
```python
def _extract_imports(self, file_path: Path) -> List[str]:
    """
    提取文件的导入语句
    
    返回：
    [
        "from ..llm import get_client_manager",
        "from ..tools import get_tool_registry",
        "import json"
    ]
    """
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        import re
        imports = []
        
        # 匹配 import xxx
        pattern1 = r'^import\s+[\w\.]+(?:\s+as\s+\w+)?'
        imports.extend(re.findall(pattern1, content, re.MULTILINE))
        
        # 匹配 from xxx import yyy
        pattern2 = r'^from\s+[\w\.]+\s+import\s+[\w\s,]+(?:\s+as\s+\w+)?'
        imports.extend(re.findall(pattern2, content, re.MULTILINE))
        
        return imports[:20]  # 限制数量
    
    except Exception as e:
        logger.debug(f"提取导入失败 {file_path}: {e}")
        return []
```

### 步骤4: 构建文件关联

**文件**: `backend/daoyoucode/agents/memory/codebase_index.py`

**任务**: 添加`_get_related_files()`方法，从引用图中提取相关文件

**新增方法**:
```python
def _get_related_files(
    self,
    file_path: str,
    reference_graph: Dict[str, Dict[str, float]],
    top_k: int = 5
) -> List[str]:
    """
    获取相关文件（基于引用图）
    
    策略：
    1. 从引用图中获取直接引用的文件
    2. 按引用次数排序
    3. 返回top_k个
    """
    if file_path not in reference_graph:
        return []
    
    # 获取引用关系 {file: count}
    refs = reference_graph[file_path]
    
    # 按引用次数排序
    sorted_refs = sorted(
        refs.items(),
        key=lambda x: x[1],
        reverse=True
    )
    
    # 返回文件路径
    return [file for file, _ in sorted_refs[:top_k]]
```

### 步骤5: 构建被调用关系

**文件**: `backend/daoyoucode/agents/memory/codebase_index.py`

**任务**: 添加`_find_callers()`方法，找到调用当前函数的文件

**新增方法**:
```python
def _find_callers(
    self,
    function_name: str,
    file_path: str,
    all_definitions: Dict[str, List[Dict]]
) -> List[str]:
    """
    找到调用这个函数的文件
    
    策略：
    1. 遍历所有definitions
    2. 找到kind="ref"且name匹配的引用
    3. 返回引用所在的文件
    """
    callers = []
    
    for other_file, defs in all_definitions.items():
        if other_file == file_path:
            continue  # 跳过自己
        
        for d in defs:
            if d.get("kind") == "ref" and d.get("name") == function_name:
                if other_file not in callers:
                    callers.append(other_file)
    
    return callers[:10]  # 限制数量
```

### 步骤6: 修改build_index()集成所有信息

**文件**: `backend/daoyoucode/agents/memory/codebase_index.py`

**任务**: 在构建chunk时，调用上述方法添加所有元数据

**修改点**:
```python
def build_index(self, ...):
    # ... 前面的逻辑不变 ...
    
    # 获取definitions和reference_graph
    definitions = repomap_tool.get_definitions(str(self.repo_path))
    reference_graph = repomap_tool.get_reference_graph(str(self.repo_path), definitions)
    pagerank_scores = repomap_tool.get_pagerank_scores(...)
    
    # 🆕 预先提取所有文件的导入关系
    file_imports = {}
    for file_path in definitions.keys():
        full_path = self.repo_path / file_path
        file_imports[file_path] = self._extract_imports(full_path)
    
    # 构建chunks
    self.chunks = []
    for file_path, defs in definitions.items():
        def_only = [d for d in defs if d.get("kind") == "def"]
        
        for d in def_only:
            code_text = self._extract_code_chunk(...)
            
            if not code_text.strip():
                continue
            
            # 🆕 提取函数调用
            calls = self._extract_calls(code_text)
            
            # 🆕 找到调用者
            called_by = self._find_callers(d["name"], file_path, definitions)
            
            # 🆕 获取相关文件
            related_files = self._get_related_files(file_path, reference_graph)
            
            # 构建增强的chunk
            chunk = {
                "path": file_path,
                "start": d["line"],
                "end": d.get("end_line", d["line"] + len(code_text.splitlines())),
                "text": code_text[:4000],
                
                # 基础元数据（阶段1）
                "type": d.get("type", "unknown"),
                "name": d.get("name", ""),
                "pagerank_score": pagerank_scores.get(file_path, 0.0),
                
                # 🆕 阶段2新增
                "parent_class": d.get("parent"),
                "scope": d.get("scope", "global"),
                "calls": calls,
                "called_by": called_by,
                "imports": file_imports.get(file_path, []),
                "related_files": related_files
            }
            
            self.chunks.append(chunk)
```

## 测试计划

### 测试1: 验证增强的chunk结构

```python
# test_enhanced_chunk.py
from pathlib import Path
from daoyoucode.agents.memory.codebase_index import CodebaseIndex

def test_enhanced_chunk_structure():
    """测试增强的chunk结构"""
    index = CodebaseIndex(Path("."))
    index.build_index(force=True)
    
    # 验证chunk数量
    assert len(index.chunks) > 0, "应该有chunks"
    
    # 验证第一个chunk的结构
    chunk = index.chunks[0]
    
    # 基础字段（阶段1）
    assert "path" in chunk
    assert "start" in chunk
    assert "end" in chunk
    assert "text" in chunk
    assert "type" in chunk
    assert "name" in chunk
    assert "pagerank_score" in chunk
    
    # 🆕 阶段2新增字段
    assert "parent_class" in chunk
    assert "scope" in chunk
    assert "calls" in chunk
    assert "called_by" in chunk
    assert "imports" in chunk
    assert "related_files" in chunk
    
    print(f"✅ Chunk结构验证通过")
    print(f"   示例chunk: {chunk['path']}::{chunk['name']}")
    print(f"   类型: {chunk['type']}")
    print(f"   父级: {chunk.get('parent_class', 'None')}")
    print(f"   作用域: {chunk['scope']}")
    print(f"   调用: {len(chunk['calls'])} 个函数")
    print(f"   被调用: {len(chunk['called_by'])} 个文件")
    print(f"   导入: {len(chunk['imports'])} 个模块")
    print(f"   相关文件: {len(chunk['related_files'])} 个")

if __name__ == "__main__":
    test_enhanced_chunk_structure()
```

### 测试2: 验证引用关系准确性

```python
# test_reference_accuracy.py
def test_reference_accuracy():
    """测试引用关系的准确性"""
    index = CodebaseIndex(Path("."))
    index.build_index(force=True)
    
    # 找到BaseAgent.execute方法
    execute_chunk = None
    for chunk in index.chunks:
        if chunk["name"] == "execute" and chunk.get("parent_class") == "BaseAgent":
            execute_chunk = chunk
            break
    
    assert execute_chunk is not None, "应该找到BaseAgent.execute"
    
    # 验证调用关系
    print(f"\n✅ BaseAgent.execute 调用关系:")
    print(f"   调用了: {execute_chunk['calls']}")
    print(f"   被调用: {execute_chunk['called_by']}")
    print(f"   相关文件: {execute_chunk['related_files']}")
    
    # 验证合理性
    assert len(execute_chunk['calls']) > 0, "execute应该调用其他函数"
    assert len(execute_chunk['called_by']) > 0, "execute应该被其他文件调用"

if __name__ == "__main__":
    test_reference_accuracy()
```

### 测试3: 性能测试

```python
# test_performance.py
import time

def test_performance():
    """测试构建索引的性能"""
    index = CodebaseIndex(Path("."))
    
    start = time.time()
    count = index.build_index(force=True)
    elapsed = time.time() - start
    
    print(f"\n✅ 性能测试:")
    print(f"   Chunks数量: {count}")
    print(f"   构建时间: {elapsed:.2f}秒")
    print(f"   平均速度: {count/elapsed:.1f} chunks/秒")
    
    # 验证性能合理
    assert elapsed < 10, "构建时间应该小于10秒"
    assert count > 100, "应该有足够的chunks"

if __name__ == "__main__":
    test_performance()
```

## 预期效果

### 数据质量提升

- ✅ Chunk包含完整的上下文信息
- ✅ 支持"找到相关文件"功能
- ✅ 支持"找到调用链"功能
- ✅ 支持"找到依赖关系"功能

### 检索能力提升

- ✅ 可以基于引用关系扩展检索结果
- ✅ 可以基于文件关联推荐相关代码
- ✅ 可以基于PageRank排序重要代码

### 用户体验提升

- ✅ 一次检索获得完整上下文
- ✅ 自动发现相关代码
- ✅ 更准确的代码推荐

## 风险控制

### 风险1: 提取准确性

**缓解措施**:
- 使用正则表达式提取（简单但有效）
- 过滤常见关键字
- 限制数量避免噪音

### 风险2: 性能影响

**缓解措施**:
- 预先提取导入关系（避免重复读文件）
- 限制相关文件数量（top_k=5）
- 限制调用者数量（top_k=10）

### 风险3: 内存占用

**缓解措施**:
- 限制每个字段的数量
- 限制文本长度（4000字符）
- 懒加载（按需加载）

## 实施时间估算

- 步骤1: 增强Definition结构 - 30分钟
- 步骤2: 提取函数调用 - 30分钟
- 步骤3: 提取导入关系 - 30分钟
- 步骤4: 构建文件关联 - 30分钟
- 步骤5: 构建被调用关系 - 30分钟
- 步骤6: 集成到build_index - 1小时
- 测试和调试 - 1小时

**总计**: 约4-5小时

## 下一步

完成阶段2后，将进入阶段3：**多层次检索**，利用这些元数据实现智能的代码检索。

---

**准备好开始实施了吗？**
