# é˜¶æ®µ4å®æ–½è®¡åˆ’ï¼šæ··åˆæ£€ç´¢

## ç›®æ ‡

ç»“åˆå¤šç§æ£€ç´¢ä¿¡å·ï¼Œè¿›ä¸€æ­¥æå‡æ£€ç´¢å‡†ç¡®æ€§å’Œé²æ£’æ€§ï¼š
1. è¯­ä¹‰æ£€ç´¢ï¼ˆå·²æœ‰ï¼‰
2. å…³é”®è¯åŒ¹é…ï¼ˆBM25ç®—æ³•ï¼‰
3. PageRankæ’åºï¼ˆå·²æœ‰ï¼‰
4. æ–‡ä»¶å…³è”ï¼ˆå·²æœ‰ï¼‰
5. æ··åˆæ‰“åˆ†ç­–ç•¥

## å½“å‰æ£€ç´¢æ–¹å¼ï¼ˆé˜¶æ®µ3ï¼‰

```python
# å¤šå±‚æ¬¡æ£€ç´¢
final_score = (
    0.5 * similarity +      # è¯­ä¹‰ç›¸ä¼¼åº¦ 50%
    0.3 * pagerank_score +  # PageRank 30%
    0.2 * position_score    # ä½ç½® 20%
)
```

**é—®é¢˜**ï¼š
- âŒ åªä¾èµ–è¯­ä¹‰ç›¸ä¼¼åº¦ï¼ˆå¯èƒ½é—æ¼å…³é”®è¯åŒ¹é…ï¼‰
- âŒ å¯¹äºç²¾ç¡®æŸ¥è¯¢ï¼ˆå¦‚å‡½æ•°åï¼‰æ•ˆæœä¸ä½³
- âŒ æ²¡æœ‰è€ƒè™‘æŸ¥è¯¢ç±»å‹ï¼ˆè‡ªç„¶è¯­è¨€ vs ä»£ç ç‰‡æ®µï¼‰

## ç›®æ ‡æ£€ç´¢æ–¹å¼ï¼ˆé˜¶æ®µ4ï¼‰

```python
# æ··åˆæ£€ç´¢
final_score = (
    0.4 * semantic_score +   # è¯­ä¹‰ç›¸ä¼¼åº¦ 40%
    0.3 * keyword_score +    # å…³é”®è¯åŒ¹é… 30%
    0.2 * pagerank_score +   # PageRank 20%
    0.1 * context_score      # ä¸Šä¸‹æ–‡ 10%
)
```

**ä¼˜åŠ¿**ï¼š
- âœ… ç»“åˆè¯­ä¹‰å’Œå…³é”®è¯ï¼ˆäº’è¡¥ï¼‰
- âœ… å¤„ç†ç²¾ç¡®æŸ¥è¯¢ï¼ˆå‡½æ•°åã€ç±»åï¼‰
- âœ… æ›´é²æ£’ï¼ˆä¸ä¾èµ–å•ä¸€ä¿¡å·ï¼‰
- âœ… è‡ªé€‚åº”æƒé‡ï¼ˆæ ¹æ®æŸ¥è¯¢ç±»å‹ï¼‰

## å®æ–½æ­¥éª¤

### æ­¥éª¤1: å®ç°BM25å…³é”®è¯åŒ¹é…

**æ–°å¢æ–¹æ³•**: `_bm25_score()`

**BM25ç®—æ³•**:
```
BM25(q, d) = Î£ IDF(qi) * (f(qi, d) * (k1 + 1)) / (f(qi, d) + k1 * (1 - b + b * |d| / avgdl))

å…¶ä¸­ï¼š
- q: æŸ¥è¯¢
- d: æ–‡æ¡£
- qi: æŸ¥è¯¢ä¸­çš„ç¬¬iä¸ªè¯
- f(qi, d): qiåœ¨dä¸­çš„é¢‘ç‡
- IDF(qi): qiçš„é€†æ–‡æ¡£é¢‘ç‡
- k1, b: è°ƒä¼˜å‚æ•°ï¼ˆé€šå¸¸k1=1.5, b=0.75ï¼‰
- |d|: æ–‡æ¡£é•¿åº¦
- avgdl: å¹³å‡æ–‡æ¡£é•¿åº¦
```

**å®ç°**:
```python
def _bm25_score(
    self,
    query: str,
    chunk: Dict,
    k1: float = 1.5,
    b: float = 0.75
) -> float:
    """
    BM25å…³é”®è¯åŒ¹é…åˆ†æ•°
    
    Args:
        query: æŸ¥è¯¢å­—ç¬¦ä¸²
        chunk: ä»£ç å—
        k1: BM25å‚æ•°ï¼ˆæ§åˆ¶è¯é¢‘é¥±å’Œåº¦ï¼‰
        b: BM25å‚æ•°ï¼ˆæ§åˆ¶é•¿åº¦å½’ä¸€åŒ–ï¼‰
    
    Returns:
        BM25åˆ†æ•°
    """
    import re
    from collections import Counter
    
    # åˆ†è¯
    query_words = re.findall(r'\w+', query.lower())
    doc_words = re.findall(r'\w+', chunk['text'].lower())
    
    if not query_words or not doc_words:
        return 0.0
    
    # è®¡ç®—è¯é¢‘
    doc_freq = Counter(doc_words)
    doc_len = len(doc_words)
    
    # è®¡ç®—å¹³å‡æ–‡æ¡£é•¿åº¦ï¼ˆä½¿ç”¨ç¼“å­˜ï¼‰
    if not hasattr(self, '_avg_doc_len'):
        total_len = sum(len(re.findall(r'\w+', c['text'])) for c in self.chunks)
        self._avg_doc_len = total_len / len(self.chunks)
    
    # è®¡ç®—IDFï¼ˆé€†æ–‡æ¡£é¢‘ç‡ï¼‰
    def idf(word):
        # åŒ…å«è¯¥è¯çš„æ–‡æ¡£æ•°
        df = sum(1 for c in self.chunks if word in c['text'].lower())
        # IDF = log((N - df + 0.5) / (df + 0.5) + 1)
        N = len(self.chunks)
        return math.log((N - df + 0.5) / (df + 0.5) + 1)
    
    # è®¡ç®—BM25åˆ†æ•°
    score = 0.0
    for word in query_words:
        if word in doc_freq:
            # è¯é¢‘
            tf = doc_freq[word]
            # IDF
            idf_score = idf(word)
            # BM25å…¬å¼
            numerator = tf * (k1 + 1)
            denominator = tf + k1 * (1 - b + b * doc_len / self._avg_doc_len)
            score += idf_score * (numerator / denominator)
    
    return score
```

### æ­¥éª¤2: å®ç°æŸ¥è¯¢ç±»å‹æ£€æµ‹

**æ–°å¢æ–¹æ³•**: `_detect_query_type()`

**æŸ¥è¯¢ç±»å‹**:
1. **ä»£ç æŸ¥è¯¢**: åŒ…å«ä»£ç å…³é”®å­—ï¼ˆdef, class, importç­‰ï¼‰
2. **å‡½æ•°åæŸ¥è¯¢**: é©¼å³°å‘½åæˆ–ä¸‹åˆ’çº¿å‘½å
3. **è‡ªç„¶è¯­è¨€æŸ¥è¯¢**: æ™®é€šå¥å­

**å®ç°**:
```python
def _detect_query_type(self, query: str) -> str:
    """
    æ£€æµ‹æŸ¥è¯¢ç±»å‹
    
    Returns:
        "code" | "function_name" | "natural_language"
    """
    import re
    
    # ä»£ç å…³é”®å­—
    code_keywords = {
        'def', 'class', 'import', 'from', 'return',
        'if', 'for', 'while', 'try', 'except',
        'async', 'await', 'lambda', 'yield'
    }
    
    words = query.lower().split()
    
    # æ£€æŸ¥æ˜¯å¦åŒ…å«ä»£ç å…³é”®å­—
    if any(word in code_keywords for word in words):
        return "code"
    
    # æ£€æŸ¥æ˜¯å¦æ˜¯å‡½æ•°åï¼ˆé©¼å³°æˆ–ä¸‹åˆ’çº¿ï¼‰
    if re.match(r'^[a-z_][a-z0-9_]*$', query.lower()) or \
       re.match(r'^[a-z][a-zA-Z0-9]*$', query):
        return "function_name"
    
    # é»˜è®¤ä¸ºè‡ªç„¶è¯­è¨€
    return "natural_language"
```

### æ­¥éª¤3: å®ç°è‡ªé€‚åº”æƒé‡

**æ–°å¢æ–¹æ³•**: `_get_adaptive_weights()`

**ç­–ç•¥**:
- ä»£ç æŸ¥è¯¢: å…³é”®è¯æƒé‡é«˜
- å‡½æ•°åæŸ¥è¯¢: ç²¾ç¡®åŒ¹é…æƒé‡é«˜
- è‡ªç„¶è¯­è¨€æŸ¥è¯¢: è¯­ä¹‰æƒé‡é«˜

**å®ç°**:
```python
def _get_adaptive_weights(self, query_type: str) -> Dict[str, float]:
    """
    æ ¹æ®æŸ¥è¯¢ç±»å‹è¿”å›è‡ªé€‚åº”æƒé‡
    
    Args:
        query_type: "code" | "function_name" | "natural_language"
    
    Returns:
        æƒé‡å­—å…¸
    """
    if query_type == "code":
        # ä»£ç æŸ¥è¯¢ï¼šå…³é”®è¯æƒé‡é«˜
        return {
            "semantic": 0.3,
            "keyword": 0.4,
            "pagerank": 0.2,
            "context": 0.1
        }
    elif query_type == "function_name":
        # å‡½æ•°åæŸ¥è¯¢ï¼šç²¾ç¡®åŒ¹é…æƒé‡é«˜
        return {
            "semantic": 0.2,
            "keyword": 0.5,
            "pagerank": 0.2,
            "context": 0.1
        }
    else:  # natural_language
        # è‡ªç„¶è¯­è¨€æŸ¥è¯¢ï¼šè¯­ä¹‰æƒé‡é«˜
        return {
            "semantic": 0.5,
            "keyword": 0.2,
            "pagerank": 0.2,
            "context": 0.1
        }
```

### æ­¥éª¤4: å®ç°ä¸Šä¸‹æ–‡åˆ†æ•°

**æ–°å¢æ–¹æ³•**: `_context_score()`

**ä¸Šä¸‹æ–‡å› ç´ **:
1. æ–‡ä»¶ç±»å‹ï¼ˆ.pyä¼˜å…ˆäº.mdï¼‰
2. æ–‡ä»¶è·¯å¾„ï¼ˆæ ¸å¿ƒæ¨¡å—ä¼˜å…ˆï¼‰
3. æœ€è¿‘ä¿®æ”¹æ—¶é—´
4. æ–‡ä»¶å¤§å°

**å®ç°**:
```python
def _context_score(self, chunk: Dict) -> float:
    """
    è®¡ç®—ä¸Šä¸‹æ–‡åˆ†æ•°
    
    è€ƒè™‘å› ç´ ï¼š
    1. æ–‡ä»¶ç±»å‹
    2. æ–‡ä»¶è·¯å¾„
    3. ä»£ç ç±»å‹ï¼ˆclass > function > variableï¼‰
    """
    score = 0.0
    
    # æ–‡ä»¶ç±»å‹æƒé‡
    file_ext = Path(chunk['path']).suffix
    ext_weights = {
        '.py': 1.0,
        '.js': 0.9,
        '.ts': 0.9,
        '.tsx': 0.9,
        '.jsx': 0.9,
        '.md': 0.5,
        '.yaml': 0.3,
        '.json': 0.3
    }
    score += ext_weights.get(file_ext, 0.5) * 0.3
    
    # æ–‡ä»¶è·¯å¾„æƒé‡ï¼ˆæ ¸å¿ƒæ¨¡å—ä¼˜å…ˆï¼‰
    path = chunk['path'].lower()
    if 'core' in path or 'agent' in path:
        score += 0.3
    elif 'test' in path:
        score += 0.1
    else:
        score += 0.2
    
    # ä»£ç ç±»å‹æƒé‡
    type_weights = {
        'class': 1.0,
        'function': 0.8,
        'method': 0.8,
        'variable': 0.5
    }
    score += type_weights.get(chunk.get('type', 'unknown'), 0.5) * 0.4
    
    return min(score, 1.0)  # å½’ä¸€åŒ–åˆ°[0, 1]
```

### æ­¥éª¤5: å®ç°æ··åˆæ£€ç´¢ä¸»æ–¹æ³•

**æ–°å¢æ–¹æ³•**: `search_hybrid()`

**åŠŸèƒ½**:
- æ•´åˆæ‰€æœ‰æ£€ç´¢ä¿¡å·
- è‡ªé€‚åº”æƒé‡
- è¿”å›æœ€ä¼˜ç»“æœ

**å®ç°**:
```python
def search_hybrid(
    self,
    query: str,
    top_k: int = 10,
    enable_multilayer: bool = True,
    enable_adaptive_weights: bool = True
) -> List[Dict[str, Any]]:
    """
    æ··åˆæ£€ç´¢ï¼ˆğŸ†• é˜¶æ®µ4ï¼‰
    
    ç»“åˆå¤šç§æ£€ç´¢ä¿¡å·ï¼š
    1. è¯­ä¹‰ç›¸ä¼¼åº¦
    2. BM25å…³é”®è¯åŒ¹é…
    3. PageRanké‡è¦æ€§
    4. ä¸Šä¸‹æ–‡ç›¸å…³æ€§
    
    Args:
        query: æŸ¥è¯¢å­—ç¬¦ä¸²
        top_k: è¿”å›ç»“æœæ•°é‡
        enable_multilayer: æ˜¯å¦å¯ç”¨å¤šå±‚æ‰©å±•
        enable_adaptive_weights: æ˜¯å¦å¯ç”¨è‡ªé€‚åº”æƒé‡
    
    Returns:
        æ··åˆæ£€ç´¢ç»“æœ
    """
    if not self.chunks:
        self.build_index()
    if not self.chunks:
        return []
    
    logger.info(f"ğŸ” æ··åˆæ£€ç´¢: {query}")
    
    # æ£€æµ‹æŸ¥è¯¢ç±»å‹
    query_type = self._detect_query_type(query)
    logger.info(f"   æŸ¥è¯¢ç±»å‹: {query_type}")
    
    # è·å–è‡ªé€‚åº”æƒé‡
    if enable_adaptive_weights:
        weights = self._get_adaptive_weights(query_type)
    else:
        weights = {
            "semantic": 0.4,
            "keyword": 0.3,
            "pagerank": 0.2,
            "context": 0.1
        }
    
    logger.info(f"   æƒé‡: semantic={weights['semantic']:.1f}, "
                f"keyword={weights['keyword']:.1f}, "
                f"pagerank={weights['pagerank']:.1f}, "
                f"context={weights['context']:.1f}")
    
    # ç¬¬1æ­¥ï¼šè·å–å€™é€‰ç»“æœ
    if enable_multilayer:
        # ä½¿ç”¨å¤šå±‚æ£€ç´¢è·å–å€™é€‰
        candidates = self.search_multilayer(
            query,
            top_k=top_k * 3,  # è·å–æ›´å¤šå€™é€‰
            enable_file_expansion=True,
            enable_reference_expansion=True
        )
    else:
        # ä½¿ç”¨å•å±‚æ£€ç´¢
        candidates = self.search(query, top_k=top_k * 3)
    
    logger.info(f"   å€™é€‰ç»“æœ: {len(candidates)} ä¸ª")
    
    # ç¬¬2æ­¥ï¼šè®¡ç®—æ··åˆåˆ†æ•°
    retriever = self._get_retriever()
    
    for chunk in candidates:
        # è¯­ä¹‰åˆ†æ•°ï¼ˆå·²æœ‰ï¼‰
        semantic_score = chunk.get('score', 0.0)
        
        # BM25å…³é”®è¯åˆ†æ•°
        keyword_score = self._bm25_score(query, chunk)
        
        # PageRankåˆ†æ•°ï¼ˆå·²æœ‰ï¼‰
        pagerank_score = chunk.get('pagerank_score', 0.0)
        
        # ä¸Šä¸‹æ–‡åˆ†æ•°
        context_score = self._context_score(chunk)
        
        # å½’ä¸€åŒ–ï¼ˆç¡®ä¿æ‰€æœ‰åˆ†æ•°åœ¨[0, 1]èŒƒå›´ï¼‰
        semantic_score = min(semantic_score, 1.0)
        keyword_score = min(keyword_score / 10.0, 1.0)  # BM25åˆ†æ•°é€šå¸¸è¾ƒå¤§
        pagerank_score = min(pagerank_score * 10, 1.0)  # PageRanké€šå¸¸è¾ƒå°
        
        # æ··åˆåˆ†æ•°
        chunk['hybrid_score'] = (
            weights['semantic'] * semantic_score +
            weights['keyword'] * keyword_score +
            weights['pagerank'] * pagerank_score +
            weights['context'] * context_score
        )
        
        # ä¿å­˜å„é¡¹åˆ†æ•°ï¼ˆç”¨äºè°ƒè¯•ï¼‰
        chunk['scores'] = {
            'semantic': semantic_score,
            'keyword': keyword_score,
            'pagerank': pagerank_score,
            'context': context_score
        }
    
    # ç¬¬3æ­¥ï¼šæŒ‰æ··åˆåˆ†æ•°æ’åº
    candidates.sort(key=lambda c: c.get('hybrid_score', 0), reverse=True)
    
    # ç¬¬4æ­¥ï¼šè¿”å›top-k
    results = candidates[:top_k]
    
    logger.info(f"   âœ… æœ€ç»ˆè¿”å›: {len(results)} ä¸ªç»“æœ")
    
    return results
```

### æ­¥éª¤6: æ·»åŠ ç¼“å­˜ä¼˜åŒ–

**ä¼˜åŒ–**: ç¼“å­˜IDFå’Œå¹³å‡æ–‡æ¡£é•¿åº¦

**å®ç°**:
```python
def _init_bm25_cache(self):
    """åˆå§‹åŒ–BM25ç¼“å­˜"""
    if hasattr(self, '_bm25_cache'):
        return
    
    import re
    from collections import Counter
    
    logger.info("ğŸ”„ åˆå§‹åŒ–BM25ç¼“å­˜...")
    
    # è®¡ç®—å¹³å‡æ–‡æ¡£é•¿åº¦
    total_len = 0
    for chunk in self.chunks:
        words = re.findall(r'\w+', chunk['text'].lower())
        total_len += len(words)
    
    self._avg_doc_len = total_len / len(self.chunks) if self.chunks else 1
    
    # è®¡ç®—æ–‡æ¡£é¢‘ç‡ï¼ˆæ¯ä¸ªè¯å‡ºç°åœ¨å¤šå°‘ä¸ªæ–‡æ¡£ä¸­ï¼‰
    self._doc_freq = Counter()
    for chunk in self.chunks:
        words = set(re.findall(r'\w+', chunk['text'].lower()))
        for word in words:
            self._doc_freq[word] += 1
    
    self._bm25_cache = True
    logger.info(f"   âœ… BM25ç¼“å­˜å·²åˆå§‹åŒ–ï¼ˆå¹³å‡é•¿åº¦: {self._avg_doc_len:.1f}ï¼‰")
```

## æµ‹è¯•è®¡åˆ’

### æµ‹è¯•1: BM25å…³é”®è¯åŒ¹é…

```python
def test_bm25_scoring():
    """æµ‹è¯•BM25å…³é”®è¯åŒ¹é…"""
    index = CodebaseIndex(Path("."))
    
    # æµ‹è¯•ç²¾ç¡®æŸ¥è¯¢
    query = "execute"
    
    # è®¡ç®—BM25åˆ†æ•°
    for chunk in index.chunks[:10]:
        score = index._bm25_score(query, chunk)
        if score > 0:
            print(f"{chunk['name']}: {score:.4f}")
```

### æµ‹è¯•2: æŸ¥è¯¢ç±»å‹æ£€æµ‹

```python
def test_query_type_detection():
    """æµ‹è¯•æŸ¥è¯¢ç±»å‹æ£€æµ‹"""
    index = CodebaseIndex(Path("."))
    
    queries = [
        "def execute",           # code
        "execute_with_timeout",  # function_name
        "å¦‚ä½•æ‰§è¡ŒAgent",         # natural_language
        "class BaseAgent",       # code
        "è¶…æ—¶å¤„ç†æœºåˆ¶"           # natural_language
    ]
    
    for query in queries:
        qtype = index._detect_query_type(query)
        print(f"{query:30s} â†’ {qtype}")
```

### æµ‹è¯•3: æ··åˆæ£€ç´¢å¯¹æ¯”

```python
def test_hybrid_vs_multilayer():
    """æµ‹è¯•æ··åˆæ£€ç´¢ vs å¤šå±‚æ£€ç´¢"""
    index = CodebaseIndex(Path("."))
    
    query = "execute"
    
    # å¤šå±‚æ£€ç´¢
    results_multi = index.search_multilayer(query, top_k=5)
    
    # æ··åˆæ£€ç´¢
    results_hybrid = index.search_hybrid(query, top_k=5)
    
    print(f"\nå¤šå±‚æ£€ç´¢:")
    for r in results_multi:
        print(f"  {r['name']}: {r.get('final_score', 0):.4f}")
    
    print(f"\næ··åˆæ£€ç´¢:")
    for r in results_hybrid:
        print(f"  {r['name']}: {r.get('hybrid_score', 0):.4f}")
        print(f"    è¯­ä¹‰={r['scores']['semantic']:.2f}, "
              f"å…³é”®è¯={r['scores']['keyword']:.2f}, "
              f"PageRank={r['scores']['pagerank']:.2f}")
```

### æµ‹è¯•4: è‡ªé€‚åº”æƒé‡

```python
def test_adaptive_weights():
    """æµ‹è¯•è‡ªé€‚åº”æƒé‡"""
    index = CodebaseIndex(Path("."))
    
    queries = [
        ("def execute", "code"),
        ("execute_with_timeout", "function_name"),
        ("å¦‚ä½•æ‰§è¡ŒAgent", "natural_language")
    ]
    
    for query, expected_type in queries:
        results = index.search_hybrid(query, top_k=3)
        
        print(f"\næŸ¥è¯¢: {query}")
        print(f"ç±»å‹: {expected_type}")
        print(f"ç»“æœ:")
        for r in results:
            print(f"  {r['name']}: {r['hybrid_score']:.4f}")
```

## é¢„æœŸæ•ˆæœ

### å‡†ç¡®æ€§æå‡

**åœºæ™¯1**: ç²¾ç¡®æŸ¥è¯¢ï¼ˆå‡½æ•°åï¼‰
- å¤šå±‚æ£€ç´¢: å¯èƒ½è¿”å›è¯­ä¹‰ç›¸ä¼¼ä½†ä¸ç›¸å…³çš„ç»“æœ
- æ··åˆæ£€ç´¢: ä¼˜å…ˆè¿”å›ç²¾ç¡®åŒ¹é…çš„ç»“æœ

**åœºæ™¯2**: ä»£ç ç‰‡æ®µæŸ¥è¯¢
- å¤šå±‚æ£€ç´¢: ä¾èµ–è¯­ä¹‰ç†è§£
- æ··åˆæ£€ç´¢: ç»“åˆå…³é”®è¯åŒ¹é…ï¼Œæ›´å‡†ç¡®

**åœºæ™¯3**: è‡ªç„¶è¯­è¨€æŸ¥è¯¢
- å¤šå±‚æ£€ç´¢: æ•ˆæœå¥½
- æ··åˆæ£€ç´¢: æ•ˆæœæ›´å¥½ï¼ˆç»“åˆå¤šç§ä¿¡å·ï¼‰

### æ€§èƒ½å½±å“

- BM25è®¡ç®—: ~0.05ç§’ï¼ˆæœ‰ç¼“å­˜ï¼‰
- æ€»ä½“æ—¶é—´: ~0.3ç§’ï¼ˆå¯æ¥å—ï¼‰

### é²æ£’æ€§æå‡

- ä¸ä¾èµ–å•ä¸€ä¿¡å·
- è‡ªé€‚åº”ä¸åŒæŸ¥è¯¢ç±»å‹
- æ›´å¥½åœ°å¤„ç†è¾¹ç¼˜æƒ…å†µ

## é£é™©æ§åˆ¶

### é£é™©1: æƒé‡è°ƒä¼˜å›°éš¾

**ç¼“è§£æªæ–½**:
- æä¾›é»˜è®¤æƒé‡
- æ”¯æŒè‡ªå®šä¹‰æƒé‡
- è®°å½•è¯¦ç»†çš„åˆ†æ•°åˆ†è§£

### é£é™©2: BM25è®¡ç®—å¼€é”€

**ç¼“è§£æªæ–½**:
- ç¼“å­˜IDFå’Œå¹³å‡é•¿åº¦
- åªå¯¹å€™é€‰ç»“æœè®¡ç®—
- ä½¿ç”¨é«˜æ•ˆçš„å®ç°

### é£é™©3: æŸ¥è¯¢ç±»å‹è¯¯åˆ¤

**ç¼“è§£æªæ–½**:
- ä¿å®ˆçš„æ£€æµ‹ç­–ç•¥
- æ”¯æŒæ‰‹åŠ¨æŒ‡å®šç±»å‹
- è®°å½•æ£€æµ‹ç»“æœ

## å®æ–½æ—¶é—´ä¼°ç®—

- æ­¥éª¤1: BM25å®ç° - 1å°æ—¶
- æ­¥éª¤2: æŸ¥è¯¢ç±»å‹æ£€æµ‹ - 30åˆ†é’Ÿ
- æ­¥éª¤3: è‡ªé€‚åº”æƒé‡ - 30åˆ†é’Ÿ
- æ­¥éª¤4: ä¸Šä¸‹æ–‡åˆ†æ•° - 30åˆ†é’Ÿ
- æ­¥éª¤5: æ··åˆæ£€ç´¢ä¸»æ–¹æ³• - 1å°æ—¶
- æ­¥éª¤6: ç¼“å­˜ä¼˜åŒ– - 30åˆ†é’Ÿ
- æµ‹è¯•å’Œè°ƒä¼˜ - 1å°æ—¶

**æ€»è®¡**: çº¦5å°æ—¶

## æ€»ç»“

é˜¶æ®µ4å°†è¿›ä¸€æ­¥æå‡æ£€ç´¢è´¨é‡ï¼š
- âœ… ç»“åˆè¯­ä¹‰å’Œå…³é”®è¯ï¼ˆäº’è¡¥ï¼‰
- âœ… è‡ªé€‚åº”ä¸åŒæŸ¥è¯¢ç±»å‹
- âœ… æ›´é²æ£’çš„æ£€ç´¢ç»“æœ
- âœ… æ›´å¥½çš„ç”¨æˆ·ä½“éªŒ

å®Œæˆé˜¶æ®µ4åï¼Œå‘é‡æ£€ç´¢ç³»ç»Ÿå°†è¾¾åˆ°ç”Ÿäº§çº§åˆ«çš„è´¨é‡ï¼

---

**å‡†å¤‡å¥½å¼€å§‹å®æ–½äº†å—ï¼Ÿ**
